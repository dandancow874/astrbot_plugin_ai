import asyncio
import itertools
import json
import os
import re

import astrbot.api.message_components as Comp
from astrbot.api import logger
from astrbot.api.event import AstrMessageEvent, filter
from astrbot.api.star import Context, Star, StarTools
from astrbot.core import AstrBotConfig
from astrbot.core.message.components import BaseMessageComponent
from astrbot.core.message.message_event_result import MessageChain
from astrbot.core.utils.session_waiter import SessionController, session_waiter

from .core import BaseProvider, Downloader, HttpManager
from .core.data import (
    CommonConfig,
    DEF_GEMINI_API_URL,
    DEF_OPENAI_API_URL,
    DEF_OPENAI_IMAGES_API_URL,
    PreferenceConfig,
    PromptConfig,
    ProviderConfig,
    ModelConfig,
)
from .core.llm_tools import BigBananaPromptTool, BigBananaTool, remove_tools
from .core.utils import clear_cache, read_file, save_images

# æç¤ºè¯å‚æ•°åˆ—è¡¨
PARAMS_LIST = [
    "min_images",
    "max_images",
    "refer_images",
    "image_size",
    "aspect_ratio",
    "google_search",
    "preset_append",
    "gather_mode",
    "model",
    "provider",
    "preset",
    "q",
]

# å‚æ•°åˆ«ç§°æ˜ å°„
PARAMS_ALIAS_MAP = {
    "append_mode": "gather_mode",
    "ar": "aspect_ratio",
    "r": "aspect_ratio",
    "p": "preset",
}

# æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
SUPPORTED_FILE_FORMATS = (
    ".png",
    ".jpg",
    ".jpeg",
    ".webp",
    ".bmp",
    ".gif",
    ".heic",
    ".heif",
)

# æä¾›å•†é…ç½®é”®åˆ—è¡¨
provider_keys = ["main_provider", "back_provider", "back_provider2"]

# éƒ¨åˆ†å¹³å°å¯¹å•å¼ å›¾ç‰‡å¤§å°æœ‰é™åˆ¶ï¼Œè¶…è¿‡é™åˆ¶éœ€è¦ä½œä¸ºæ–‡ä»¶å‘é€
MAX_SIZE_BYTES = 10 * 1024 * 1024  # 10MB
# é¢„è®¡ç®— Base64 é•¿åº¦é˜ˆå€¼ (å‘ä¸‹å–æ•´)ï¼Œbase64ç¼–ç çº¦ä¸ºåŸå§‹æ•°æ®çš„4/3å€
MAX_SIZE_B64_LEN = int(MAX_SIZE_BYTES * 4 / 3)


class BigBanana(Star):
    MAX_CONCURRENT_JOBS = 8

    @staticmethod
    def _normalize_api_url(api_type: str, api_url: str | None) -> str:
        url = (api_url or "").strip()
        if api_type == "Gemini":
            if not url:
                return DEF_GEMINI_API_URL
            url = url.rstrip("/")
            if url.endswith("/v1beta") or url.endswith("/v1"):
                return f"{url}/models"
            if "/models" in url:
                return url
            if "/v1beta/" not in url and "/v1/" not in url and url.count("/") <= 2:
                return f"{url}/v1beta/models"
            return url
        if api_type == "OpenAI_Chat":
            if not url:
                return DEF_OPENAI_API_URL
            url = url.rstrip("/")
            if "chat/completions" in url:
                return url
            if url.endswith("/v1"):
                return f"{url}/chat/completions"
            if url.endswith("/v1/async"):
                return f"{url}/chat/completions"
            if "/v1/" not in url and url.count("/") <= 2:
                return f"{url}/v1/chat/completions"
            return url
        if api_type == "OpenAI_Images":
            if not url:
                return DEF_OPENAI_IMAGES_API_URL
            url = url.rstrip("/")
            if "images/generations" in url:
                return url
            if "images/edits" in url or "images/variations" in url:
                return url
            return url
        return url.rstrip("/")

    @staticmethod
    def _parse_keys(raw: object) -> list[str]:
        if not isinstance(raw, str):
            return []
        parts = raw.replace("\r\n", "\n").replace("\r", "\n").split("\n")
        tokens: list[str] = []
        for part in parts:
            tokens.extend(part.split(","))
        return [t.strip() for t in tokens if t.strip()]

    def _collect_image_urls(self, event: AstrMessageEvent) -> list[str]:
        image_urls: list[str] = []
        for comp in event.get_messages():
            if isinstance(comp, Comp.Reply) and getattr(comp, "chain", None):
                quote_chain = comp.chain
                if not isinstance(quote_chain, list) and hasattr(quote_chain, "chain"):
                    quote_chain = getattr(quote_chain, "chain", None)
                for quote in quote_chain or []:
                    if isinstance(quote, Comp.Image) and quote.url:
                        image_urls.append(quote.url)
                    elif (
                        isinstance(quote, Comp.File)
                        and quote.url
                        and quote.url.startswith("http")
                        and quote.url.lower().endswith(SUPPORTED_FILE_FORMATS)
                    ):
                        image_urls.append(quote.url)
            elif isinstance(comp, Comp.Image) and comp.url:
                image_urls.append(comp.url)
            elif (
                isinstance(comp, Comp.File)
                and comp.url
                and comp.url.startswith("http")
                and comp.url.lower().endswith(SUPPORTED_FILE_FORMATS)
            ):
                image_urls.append(comp.url)
        return image_urls

    async def _try_call_platform_api(
        self, event: AstrMessageEvent, action: str, params: dict
    ) -> object | None:
        candidates: list[object] = [event]
        for attr in ("bot", "_bot", "platform", "client", "_client"):
            obj = getattr(event, attr, None)
            if obj is not None:
                candidates.append(obj)

        for target in candidates:
            for method_name in ("call_action", "call_api", "api_call", "request"):
                method = getattr(target, method_name, None)
                if not callable(method):
                    continue
                try:
                    return await method(action, **params)
                except TypeError:
                    try:
                        return await method(action, params)
                    except Exception:
                        continue
                except Exception:
                    continue
        return None

    async def _collect_reply_image_urls(
        self, event: AstrMessageEvent, reply_comp: object
    ) -> tuple[list[str], str]:
        urls: list[str] = []
        reply_sender_id = str(getattr(reply_comp, "sender_id", "") or "")

        quote_chain = getattr(reply_comp, "chain", None)
        if quote_chain is not None:
            if not isinstance(quote_chain, list) and hasattr(quote_chain, "chain"):
                quote_chain = getattr(quote_chain, "chain", None)
            for quote in quote_chain or []:
                if isinstance(quote, Comp.Image) and quote.url:
                    urls.append(quote.url)
                elif (
                    isinstance(quote, Comp.File)
                    and quote.url
                    and quote.url.startswith("http")
                    and quote.url.lower().endswith(SUPPORTED_FILE_FORMATS)
                ):
                    urls.append(quote.url)
            if urls:
                return urls, reply_sender_id

        reply_id = None
        for key in ("id", "message_id", "msg_id", "reply_id"):
            value = getattr(reply_comp, key, None)
            if value is None:
                continue
            if isinstance(value, (int, str)) and str(value).strip():
                reply_id = str(value).strip()
                break

        if not reply_id:
            return [], reply_sender_id

        resp = await self._try_call_platform_api(
            event, "get_msg", {"message_id": int(reply_id)}
        )
        if resp is None:
            return [], reply_sender_id

        data = resp
        if isinstance(resp, dict) and "data" in resp:
            data = resp.get("data")

        message = None
        if isinstance(data, dict):
            message = (
                data.get("message")
                or data.get("message_chain")
                or data.get("messageChain")
                or data.get("raw_message")
            )

        def append_if_media(url: object):
            if not isinstance(url, str):
                return
            u = url.strip()
            if not u:
                return
            if u.startswith("http") and u.lower().endswith(SUPPORTED_FILE_FORMATS):
                urls.append(u)
                return
            if u.startswith("http") and any(ext in u.lower() for ext in SUPPORTED_FILE_FORMATS):
                urls.append(u)

        if isinstance(message, list):
            for seg in message:
                if not isinstance(seg, dict):
                    continue
                t = seg.get("type")
                d = seg.get("data") if isinstance(seg.get("data"), dict) else {}
                if t == "image":
                    append_if_media(d.get("url") or d.get("file"))
                elif t == "file":
                    append_if_media(d.get("url") or d.get("name") or d.get("file"))
            return urls, reply_sender_id

        if isinstance(message, str) and message:
            for m in re.finditer(r"url=([^,\\]]+)", message):
                append_if_media(m.group(1))
            for m in re.finditer(r"file=([^,\\]]+)", message):
                append_if_media(m.group(1))
        return urls, reply_sender_id

    async def _image_to_prompt(
        self, event: AstrMessageEvent, prompt: str, min_required_images: int
    ) -> str:
        if not hasattr(self, "http_manager") or not hasattr(self, "downloader"):
            return "âŒ æ’ä»¶æœªåˆå§‹åŒ–å®Œæˆï¼Œè¯·ç¨åå†è¯•"

        itp_conf = self.conf.get("Image-to-Prompt", {})
        if not isinstance(itp_conf, dict):
            itp_conf = {}

        if not bool(itp_conf.get("enabled", True)):
            return "âŒ Image-to-Prompt æœªå¯ç”¨"

        model = str(itp_conf.get("model", "") or "").strip()
        system_prompt = str(itp_conf.get("system_prompt", "") or "").strip()

        primary_conf = itp_conf.get("primary", {})
        if not isinstance(primary_conf, dict):
            primary_conf = {}

        api_url = primary_conf.get("api_url", itp_conf.get("api_url", ""))
        api_key_raw = primary_conf.get("api_key", itp_conf.get("api_key", ""))
        tls_verify = primary_conf.get("tls_verify", itp_conf.get("tls_verify", True))
        impersonate = primary_conf.get("impersonate", itp_conf.get("impersonate", ""))
        api_url = self._normalize_api_url("OpenAI_Chat", str(api_url or ""))
        keys = self._parse_keys(api_key_raw)

        if not keys:
            return "âŒ Image-to-Prompt æœªé…ç½® API Key"

        image_urls = self._collect_image_urls(event)
        required = max(1, int(min_required_images or 1))
        if len(image_urls) < required:
            return f"âŒ éœ€è¦è‡³å°‘ {required} å¼ å›¾ç‰‡"

        b64_images = await self.downloader.fetch_images(image_urls)
        if not b64_images:
            return "âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥"

        images_content = []
        for mime, b64 in b64_images:
            images_content.append(
                {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{b64}"}}
            )

        messages: list[dict] = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append(
            {
                "role": "user",
                "content": [{"type": "text", "text": prompt}, *images_content],
            }
        )

        body = {"messages": messages, "stream": False, "max_tokens": 1024}
        if model:
            body["model"] = model
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {keys[0]}",
        }

        try:
            req_kwargs = {
                "timeout": self.common_config.timeout,
                "proxy": self.common_config.proxy,
                "verify": bool(tls_verify),
            }
            if isinstance(impersonate, str) and impersonate.strip():
                req_kwargs["impersonate"] = impersonate.strip()
            response = await self.http_manager._get_curl_session().post(
                url=api_url,
                headers=headers,
                json=body,
                **req_kwargs,
            )
            try:
                result = response.json()
            except json.JSONDecodeError as e:
                logger.error(
                    f"[BIG BANANA] Image-to-Prompt JSONååºåˆ—åŒ–é”™è¯¯: {e}ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}ï¼Œå“åº”å†…å®¹ï¼š{response.text[:1024]}"
                )
                return "âŒ åæ¨å¤±è´¥ï¼šå“åº”å†…å®¹æ ¼å¼é”™è¯¯"
            if response.status_code != 200:
                msg = None
                if isinstance(result, dict):
                    if isinstance(result.get("message"), str):
                        msg = result.get("message")
                    err = result.get("error")
                    if not msg and isinstance(err, dict):
                        msg = err.get("message")
                logger.error(
                    f"[BIG BANANA] Image-to-Prompt å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å“åº”å†…å®¹: {response.text[:1024]}"
                )
                return f"âŒ åæ¨å¤±è´¥ï¼š{msg or f'çŠ¶æ€ç  {response.status_code}'}"

            choices = result.get("choices") if isinstance(result, dict) else None
            if not isinstance(choices, list) or not choices:
                return "âŒ åæ¨å¤±è´¥ï¼šå“åº”ç¼ºå°‘ choices"
            message = choices[0].get("message", {}) if isinstance(choices[0], dict) else {}
            content = message.get("content", "")
            if isinstance(content, list):
                parts: list[str] = []
                for item in content:
                    if not isinstance(item, dict):
                        continue
                    if item.get("type") == "text" and isinstance(item.get("text"), str):
                        parts.append(item["text"])
                content = "\n".join(p for p in parts if p.strip())
            if not isinstance(content, str) or not content.strip():
                return "âŒ åæ¨å¤±è´¥ï¼šå“åº”ç¼ºå°‘å†…å®¹"
            return content.strip()
        except Exception as e:
            logger.error(f"[BIG BANANA] Image-to-Prompt è¯·æ±‚é”™è¯¯: {e}", exc_info=True)
            return "âŒ åæ¨å¤±è´¥ï¼šè¯·æ±‚é”™è¯¯"

    def __init__(self, context: Context, config: AstrBotConfig):
        super().__init__(context)
        self.conf = config
        # åˆå§‹åŒ–æç¤ºè¯é…ç½®
        self.init_prompts()
        self.user_selected_provider_model: dict[str, str] = {}
        # ç™½åå•é…ç½®
        self.whitelist_config = self.conf.get("whitelist_config", {})
        # ç¾¤ç»„ç™½åå•ï¼Œåˆ—è¡¨æ˜¯å¼•ç”¨ç±»å‹
        self.group_whitelist_enabled = self.whitelist_config.get("enabled", False)
        self.group_whitelist = self.whitelist_config.get("whitelist", [])
        # ç”¨æˆ·ç™½åå•
        self.user_whitelist_enabled = self.whitelist_config.get("user_enabled", False)
        self.user_whitelist = self.whitelist_config.get("user_whitelist", [])

        nanobanana_conf = self.conf.get("nanobanana_config", {})
        if not isinstance(nanobanana_conf, dict):
            nanobanana_conf = {}
        nanobanana_whitelist = nanobanana_conf.get("whitelist", {})
        if not isinstance(nanobanana_whitelist, dict):
            nanobanana_whitelist = {}
        self.nanobanana_group_whitelist_enabled = bool(
            nanobanana_whitelist.get("enabled", False)
        )
        self.nanobanana_group_whitelist = nanobanana_whitelist.get("whitelist", [])
        self.nanobanana_user_whitelist_enabled = bool(
            nanobanana_whitelist.get("user_enabled", False)
        )
        self.nanobanana_user_whitelist = nanobanana_whitelist.get("user_whitelist", [])

        # å‰ç¼€é…ç½®
        prefix_config = self.conf.get("prefix_config", {})
        self.coexist_enabled = prefix_config.get("coexist_enabled", False)
        self.prefix_list = prefix_config.get("prefix_list", [])

        # æ•°æ®ç›®å½•
        data_dir = StarTools.get_data_dir("astrbot_plugin_big_banana")
        self.refer_images_dir = data_dir / "refer_images"
        self.save_dir = data_dir / "save_images"
        # ä¸´æ—¶æ–‡ä»¶ç›®å½•
        self.temp_dir = data_dir / "temp_images"

        # å›¾ç‰‡æŒä¹…åŒ–
        self.save_images = self.conf.get("save_images", {}).get("local_save", False)

        # æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡æ˜ å°„
        self.running_tasks: dict[str, asyncio.Task] = {}
        self.job_semaphore: asyncio.Semaphore | None = None

    async def initialize(self):
        """å¯é€‰æ‹©å®ç°å¼‚æ­¥çš„æ’ä»¶åˆå§‹åŒ–æ–¹æ³•ï¼Œå½“å®ä¾‹åŒ–è¯¥æ’ä»¶ç±»ä¹‹åä¼šè‡ªåŠ¨è°ƒç”¨è¯¥æ–¹æ³•ã€‚"""
        # åˆå§‹åŒ–æ–‡ä»¶ç›®å½•
        os.makedirs(self.refer_images_dir, exist_ok=True)
        os.makedirs(self.temp_dir, exist_ok=True)
        if self.save_images:
            os.makedirs(self.save_dir, exist_ok=True)

        # å®ä¾‹åŒ–ç±»
        self.preference_config = PreferenceConfig(
            **self.conf.get("preference_config", {})
        )
        self.common_config = CommonConfig(**self.conf.get("common_config", {}))
        self.prompt_config = PromptConfig(**self.conf.get("prompt_config", {}))
        self.http_manager = HttpManager()
        curl_session = self.http_manager._get_curl_session()
        self.downloader = Downloader(curl_session, self.common_config)
        self.job_semaphore = asyncio.Semaphore(self.MAX_CONCURRENT_JOBS)

        # æ³¨å†Œæä¾›å•†ç±»å‹å®ä¾‹
        self.init_providers()
        self.init_prompts()

        # æ£€æŸ¥é…ç½®æ˜¯å¦å¯ç”¨å‡½æ•°è°ƒç”¨å·¥å…·
        if self.conf.get("llm_tool_settings", {}).get("llm_tool_enabled", False):
            self.context.add_llm_tools(BigBananaTool(plugin=self))
            logger.info("å·²æ³¨å†Œå‡½æ•°è°ƒç”¨å·¥å…·: banana_image_generation")
            self.context.add_llm_tools(BigBananaPromptTool(plugin=self))
            logger.info("å·²æ³¨å†Œå‡½æ•°è°ƒç”¨å·¥å…·: banana_preset_prompt")

    def init_providers(self):
        """è§£ææä¾›å•†é…ç½®"""
        # æ¨¡å‹é…ç½®åˆ—è¡¨
        self.models: list[ModelConfig] = []
        # æä¾›å•†å®ä¾‹æ˜ å°„
        self.provider_map: dict[str, BaseProvider] = {}
        
        # 1. è·å–æ¨¡å‹é…ç½®åˆ—è¡¨
        models_data = self.conf.get("models", [])
        
        # å…¼å®¹æ—§é…ç½®ï¼šå¦‚æœ models ä¸ºç©ºï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ extra_models æˆ– default_model å¹¶è¿ç§»
        # è¿™æ˜¯ä¸€ä¸ªä¸´æ—¶è¿ç§»é€»è¾‘ï¼Œé˜²æ­¢ç”¨æˆ·æ›´æ–°åé…ç½®ä¸¢å¤±
        if not models_data:
            if "extra_models" in self.conf:
                models_data.extend(self.conf.get("extra_models", []))
            
            if "default_model" in self.conf:
                default_model = self.conf.get("default_model")
                if default_model:
                     # æ„é€ ä¸€ä¸ª Model å¯¹è±¡
                     models_data.insert(0, {
                         "name": "é»˜è®¤ç”»å›¾é…ç½®",
                         "triggers": default_model.get("triggers", []),
                         "providers": default_model.get("providers", []),
                         "enabled": default_model.get("enabled", True)
                     })
            
            # å¦‚æœä»æ—§é…ç½®è¿ç§»äº†æ•°æ®ï¼Œä¿å­˜å› models
            if models_data:
                self.conf["models"] = models_data
                # æ¸…ç†æ—§é”®ï¼ˆå¯é€‰ï¼Œä½†ä¸ºäº†ä¿æŒé…ç½®æ•´æ´æœ€å¥½æ¸…ç†ï¼‰
                self.conf.pop("extra_models", None)
                self.conf.pop("default_model", None)
                self.conf.save_config()

        # å¦‚æœä»ç„¶ä¸ºç©ºï¼Œä¸”æ˜¯é¦–æ¬¡è¿è¡Œï¼Œå¯èƒ½ä¼šè¯»å–é»˜è®¤é…ç½®ï¼ˆç”± schema å®šä¹‰ï¼‰
        if not isinstance(models_data, list):
            models_data = []

        updated_models = False

        def parse_keys(raw: object) -> list[str]:
            if not isinstance(raw, str):
                return []
            parts = raw.replace("\r\n", "\n").replace("\r", "\n").split("\n")
            tokens: list[str] = []
            for part in parts:
                tokens.extend(part.split(","))
            return [t.strip() for t in tokens if t.strip()]

        def upsert_fixed_model(
            conf_key: str,
            name: str,
            default_triggers: list[str],
            default_provider_stub: dict,
            insert_index: int,
        ) -> None:
            nonlocal updated_models, models_data

            model_conf = self.conf.get(conf_key, {})
            if not isinstance(model_conf, dict):
                model_conf = {}

            enabled = bool(model_conf.get("enabled", True))

            providers = model_conf.get("providers", None)
            if not isinstance(providers, list) or not providers:
                provider_list: list[dict] = []

                primary_conf = model_conf.get("primary", {})
                if not isinstance(primary_conf, dict):
                    primary_conf = {}

                def build_provider_item(conf: dict, suffix: str) -> dict:
                    api_base_mapping = {
                        "t8star": "https://ai.t8star.cn",
                        "zhenzhen": "https://ai.t8star.cn",
                        "hk": "https://hk-api.gptbest.vip",
                        "us": "https://api.gptbest.vip",
                        "grsai": "https://grsaiapi.com",
                    }
                    api_type = conf.get("api_type", None)
                    if not isinstance(api_type, str) or not api_type.strip():
                        api_type = default_provider_stub.get("api_type")
                    api_type = str(api_type).strip()
                    if conf_key == "nanobanana_config":
                        if suffix == "ä¸»":
                            api_type = "OpenAI_Images"
                        elif suffix == "å¤‡" and not str(conf.get("api_type", "") or "").strip():
                            api_type = "OpenAI_Chat"

                    item = dict(default_provider_stub)
                    item["api_type"] = api_type

                    model_name = conf.get("model", None)
                    if isinstance(model_name, str) and model_name.strip():
                        item["model"] = model_name.strip()

                    url = conf.get("api_url", model_conf.get("api_url", ""))
                    api_base = conf.get("api_base", None)
                    if isinstance(api_base, str) and api_base.strip():
                        api_base = api_base.strip()
                        if api_base == "ip":
                            custom_ip = conf.get("custom_ip", None)
                            if isinstance(custom_ip, str) and custom_ip.strip():
                                url = custom_ip.strip()
                        elif api_base in api_base_mapping:
                            url = api_base_mapping[api_base]
                    item["api_url"] = url

                    tls_verify = conf.get("tls_verify", None)
                    if isinstance(tls_verify, bool):
                        item["tls_verify"] = tls_verify
                    impersonate = conf.get("impersonate", None)
                    if isinstance(impersonate, str) and impersonate.strip():
                        item["impersonate"] = impersonate.strip()

                    if (
                        item.get("api_type") == "OpenAI_Chat"
                        and isinstance(url, str)
                        and "/images/" in url.lower()
                    ):
                        item["api_type"] = "OpenAI_Images"

                    if api_type == "Vertex_AI_Anonymous":
                        item["keys"] = []
                        base_name = "VertexåŒ¿å"
                    else:
                        key = conf.get("api_key", model_conf.get("api_key", ""))
                        item["keys"] = parse_keys(key)
                        base_name = str(default_provider_stub.get("name", name))

                    item["name"] = f"{base_name}_{suffix}"
                    return item

                primary_data = build_provider_item(primary_conf, "ä¸»")
                provider_list.append(primary_data)

                secondary_conf = model_conf.get("secondary", {})
                if not isinstance(secondary_conf, dict):
                    secondary_conf = {}
                secondary_url = secondary_conf.get("api_url", "")
                secondary_key = secondary_conf.get("api_key", "")
                secondary_api_type = secondary_conf.get("api_type", "")
                secondary_model = secondary_conf.get("model", "")
                if conf_key == "nanobanana_config" and not (
                    str(secondary_api_type).strip()
                    or str(secondary_url).strip()
                    or str(secondary_key).strip()
                    or str(secondary_model).strip()
                ):
                    secondary_url = "https://grsaiapi.com"
                    secondary_api_type = "OpenAI_Chat"
                    secondary_model = "nano-banana-pro"
                if (
                    str(secondary_api_type).strip() == "Vertex_AI_Anonymous"
                    or str(secondary_url).strip()
                    or str(secondary_key).strip()
                    or str(secondary_model).strip()
                ):
                    secondary_data = build_provider_item(
                        {
                            "api_type": secondary_api_type,
                            "api_url": secondary_url,
                            "api_key": secondary_key,
                            "model": secondary_model,
                        },
                        "å¤‡",
                    )
                    provider_list.append(secondary_data)

                providers = provider_list

            triggers = default_triggers

            new_data = {
                "name": name,
                "triggers": triggers,
                "providers": providers,
                "enabled": enabled,
            }

            target = next(
                (m for m in models_data if isinstance(m, dict) and m.get("name") == name),
                None,
            )
            if target is None:
                models_data.insert(insert_index, new_data)
                updated_models = True
                return

            if (
                target.get("triggers") != triggers
                or target.get("providers") != providers
                or target.get("enabled", True) != enabled
            ):
                target.update(new_data)
                updated_models = True

        upsert_fixed_model(
            conf_key="nanobanana_config",
            name="nano-banana",
            default_triggers=["bnn", "bnt", "bna"],
            default_provider_stub={
                "name": "nano-bananaè´¦å·",
                "enabled": True,
                "api_type": "OpenAI_Images",
                "keys": [],
                "api_url": "https://ai.t8star.cn",
                "model": "nano-banana-2-2k",
                "stream": False,
            },
            insert_index=0,
        )
        upsert_fixed_model(
            conf_key="zimage_config",
            name="Z-Image-Turbo",
            default_triggers=["zimg"],
            default_provider_stub={
                "name": "Z-Imageè´¦å·",
                "enabled": True,
                "api_type": "OpenAI_Images",
                "keys": [],
                "api_url": DEF_OPENAI_IMAGES_API_URL,
                "model": "Z-Image-Turbo",
                "stream": False,
            },
            insert_index=1,
        )
        upsert_fixed_model(
            conf_key="qwen_edit_2511_config",
            name="Qwen-Image-Edit-2511",
            default_triggers=["edit"],
            default_provider_stub={
                "name": "Qwenè´¦å·",
                "enabled": True,
                "api_type": "OpenAI_Chat",
                "keys": [],
                "api_url": DEF_OPENAI_API_URL,
                "model": "Qwen-Image-Edit-2511",
                "stream": False,
            },
            insert_index=2,
        )
        upsert_fixed_model(
            conf_key="flow2api_config",
            name="flow2api bt1 æ–‡ç”Ÿå›¾ æ¨ªå±",
            default_triggers=["bt1"],
            default_provider_stub={
                "name": "flow2api",
                "enabled": True,
                "api_type": "OpenAI_Chat",
                "keys": [],
                "api_url": "http://192.168.2.109:8300/v1/chat/completions",
                "model": "gemini-3.0-pro-image-landscape",
                "stream": True,
            },
            insert_index=3,
        )
        upsert_fixed_model(
            conf_key="flow2api_config",
            name="flow2api bt2 æ–‡ç”Ÿå›¾ ç«–å±",
            default_triggers=["bt2"],
            default_provider_stub={
                "name": "flow2api",
                "enabled": True,
                "api_type": "OpenAI_Chat",
                "keys": [],
                "api_url": "http://192.168.2.109:8300/v1/chat/completions",
                "model": "gemini-3.0-pro-image-portrait",
                "stream": True,
            },
            insert_index=4,
        )
        upsert_fixed_model(
            conf_key="flow2api_config",
            name="flow2api bp1 å›¾ç”Ÿå›¾ æ¨ªå±",
            default_triggers=["bp1"],
            default_provider_stub={
                "name": "flow2api",
                "enabled": True,
                "api_type": "OpenAI_Chat",
                "keys": [],
                "api_url": "http://192.168.2.109:8300/v1/chat/completions",
                "model": "gemini-3.0-pro-image-landscape",
                "stream": True,
            },
            insert_index=5,
        )
        upsert_fixed_model(
            conf_key="flow2api_config",
            name="flow2api bp2 å›¾ç”Ÿå›¾ ç«–å±",
            default_triggers=["bp2"],
            default_provider_stub={
                "name": "flow2api",
                "enabled": True,
                "api_type": "OpenAI_Chat",
                "keys": [],
                "api_url": "http://192.168.2.109:8300/v1/chat/completions",
                "model": "gemini-3.0-pro-image-portrait",
                "stream": True,
            },
            insert_index=6,
        )
        upsert_fixed_model(
            conf_key="flow2api_config",
            name="flow2api tv1 æ–‡ç”Ÿè§†é¢‘ æ¨ªå±",
            default_triggers=["tv1"],
            default_provider_stub={
                "name": "flow2api",
                "enabled": True,
                "api_type": "OpenAI_Chat",
                "keys": [],
                "api_url": "http://192.168.2.109:8300/v1/chat/completions",
                "model": "veo_3_1_t2v_fast_landscape",
                "stream": True,
            },
            insert_index=7,
        )
        upsert_fixed_model(
            conf_key="flow2api_config",
            name="flow2api tv2 æ–‡ç”Ÿè§†é¢‘ ç«–å±",
            default_triggers=["tv2"],
            default_provider_stub={
                "name": "flow2api",
                "enabled": True,
                "api_type": "OpenAI_Chat",
                "keys": [],
                "api_url": "http://192.168.2.109:8300/v1/chat/completions",
                "model": "veo_3_1_t2v_fast_portrait",
                "stream": True,
            },
            insert_index=8,
        )
        upsert_fixed_model(
            conf_key="flow2api_config",
            name="flow2api iv1 é¦–å°¾å¸§å›¾ç”Ÿè§†é¢‘ æ¨ªå±",
            default_triggers=["iv1"],
            default_provider_stub={
                "name": "flow2api",
                "enabled": True,
                "api_type": "OpenAI_Chat",
                "keys": [],
                "api_url": "http://192.168.2.109:8300/v1/chat/completions",
                "model": "veo_3_1_i2v_s_fast_fl_landscape",
                "stream": True,
            },
            insert_index=9,
        )
        upsert_fixed_model(
            conf_key="flow2api_config",
            name="flow2api iv2 é¦–å°¾å¸§å›¾ç”Ÿè§†é¢‘ ç«–å±",
            default_triggers=["iv2"],
            default_provider_stub={
                "name": "flow2api",
                "enabled": True,
                "api_type": "OpenAI_Chat",
                "keys": [],
                "api_url": "http://192.168.2.109:8300/v1/chat/completions",
                "model": "veo_3_1_i2v_s_fast_fl_portrait",
                "stream": True,
            },
            insert_index=10,
        )
        upsert_fixed_model(
            conf_key="flow2api_config",
            name="flow2api rv1 å›¾ç”Ÿè§†é¢‘ æ¨ªå±",
            default_triggers=["rv1"],
            default_provider_stub={
                "name": "flow2api",
                "enabled": True,
                "api_type": "OpenAI_Chat",
                "keys": [],
                "api_url": "http://192.168.2.109:8300/v1/chat/completions",
                "model": "veo_3_0_r2v_fast_landscape",
                "stream": True,
            },
            insert_index=11,
        )
        upsert_fixed_model(
            conf_key="flow2api_config",
            name="flow2api rv2 å›¾ç”Ÿè§†é¢‘ ç«–å±",
            default_triggers=["rv2"],
            default_provider_stub={
                "name": "flow2api",
                "enabled": True,
                "api_type": "OpenAI_Chat",
                "keys": [],
                "api_url": "http://192.168.2.109:8300/v1/chat/completions",
                "model": "veo_3_0_r2v_fast_portrait",
                "stream": True,
            },
            insert_index=12,
        )

        if updated_models:
            self.conf["models"] = models_data
            self.conf.save_config()
        
        for model_data in models_data:
            # Parse ProviderConfig list
            providers_data = model_data.get("providers", [])
            providers = []
            for provider_data in providers_data:
                if provider_data.get("enabled", False):
                    # è¿‡æ»¤æ‰ä¸åœ¨ ProviderConfig ä¸­çš„å­—æ®µ
                    payload = {
                        k: v
                        for k, v in provider_data.items()
                        if k in ProviderConfig.__annotations__
                    }
                    payload.setdefault("keys", [])
                    payload["api_url"] = self._normalize_api_url(
                        payload.get("api_type", ""), payload.get("api_url", "")
                    )
                    p_config = ProviderConfig(**payload)
                    providers.append(p_config)
            
            # Create ModelConfig
            model_config = ModelConfig(
                name=model_data.get("name", "Unknown"),
                triggers=model_data.get("triggers", []),
                providers=providers,
                enabled=model_data.get("enabled", True)
            )
            if model_config.enabled:
                self.models.append(model_config)

        # 3. æ”¶é›†æ‰€æœ‰éœ€è¦çš„ API ç±»å‹å¹¶å®ä¾‹åŒ–
        needed_api_types = set()
        for model in self.models:
            for provider in model.providers:
                needed_api_types.add(provider.api_type)

        # å®ä¾‹åŒ–æä¾›å•†ç±»
        for api_type in needed_api_types:
            provider_cls = BaseProvider.get_provider_class(api_type)
            if provider_cls is None:
                logger.warning(
                    f"æœªæ‰¾åˆ°æä¾›å•†ç±»å‹å¯¹åº”çš„æä¾›å•†ç±»ï¼š{api_type}ï¼Œè·³è¿‡è¯¥æä¾›å•†é…ç½®"
                )
                continue
            self.provider_map[api_type] = provider_cls(
                config=self.conf,
                common_config=self.common_config,
                prompt_config=self.prompt_config,
                session=self.http_manager._get_curl_session(),
                downloader=self.downloader,
                aiohttp_session=self.http_manager._get_aiohttp_session(),
            )

    def init_prompts(self):
        """åˆå§‹åŒ–æç¤ºè¯é…ç½®"""
        # é¢„è®¾æç¤ºè¯åˆ—è¡¨
        self.prompt_list = self.conf.get("prompt", [])
        self.prompt_dict = {}
        existing_cmds: set[str] = set()
        for item in self.prompt_list:
            cmd_list, params = self.parsing_prompt_params(item)
            for cmd in cmd_list:
                existing_cmds.add(cmd)
                self.prompt_dict[cmd] = params

        fixed_prompts: dict[str, str] = {
            "bt1": "bt1 {{user_text}} --min_images 0",
            "bt2": "bt2 {{user_text}} --min_images 0",
            "bp1": "bp1 {{user_text}} --min_images 1",
            "bp2": "bp2 {{user_text}} --min_images 1",
            "tv1": "tv1 {{user_text}} --min_images 0",
            "tv2": "tv2 {{user_text}} --min_images 0",
            "iv1": "iv1 {{user_text}} --min_images 2",
            "iv2": "iv2 {{user_text}} --min_images 2",
            "rv1": "rv1 {{user_text}} --min_images 1",
            "rv2": "rv2 {{user_text}} --min_images 1",
        }
        updated_prompts = False
        for trigger, prompt_line in fixed_prompts.items():
            if trigger in existing_cmds:
                continue
            cmd_list, params = self.parsing_prompt_params(prompt_line)
            self.prompt_list.append(prompt_line)
            updated_prompts = True
            for cmd in cmd_list:
                existing_cmds.add(cmd)
                self.prompt_dict[cmd] = params

        # å°†æ¨¡å‹è§¦å‘è¯ä¹ŸåŠ å…¥åˆ° prompt_dict ä¸­ï¼Œä»¥ä¾¿åœ¨ on_message ä¸­èƒ½é€šè¿‡æ£€æŸ¥
        # å¦‚æœè§¦å‘è¯å·²å­˜åœ¨ï¼ˆå³æœ‰é¢„è®¾æç¤ºè¯ï¼‰ï¼Œåˆ™ä¸åšå¤„ç†ï¼ˆé¢„è®¾æç¤ºè¯ä¼˜å…ˆï¼‰
        # å¦‚æœè§¦å‘è¯ä¸å­˜åœ¨ï¼Œåˆ™æ·»åŠ ä¸€ä¸ªé»˜è®¤çš„æç¤ºè¯é…ç½®
        if hasattr(self, "models"):
            for model in self.models:
                for trigger in model.triggers:
                    if trigger not in self.prompt_dict:
                        self.prompt_dict[trigger] = {
                            "prompt": "{{user_text}}",
                            "__model_name__": model.name
                        }
                    else:
                        # å¦‚æœå·²å­˜åœ¨ï¼Œæ ‡è®°è¯¥æç¤ºè¯å±äºå“ªä¸ªæ¨¡å‹ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
                        if "__model_name__" not in self.prompt_dict[trigger]:
                            self.prompt_dict[trigger]["__model_name__"] = model.name

        if updated_prompts:
            self.conf["prompt"] = self.prompt_list
            self.conf.save_config()

    def parsing_prompt_params(self, prompt: str) -> tuple[list[str], dict]:
        """è§£ææç¤ºè¯ä¸­çš„å‚æ•°ï¼Œè‹¥æ²¡æœ‰æŒ‡å®šå‚æ•°åˆ™ä½¿ç”¨é»˜è®¤å€¼å¡«å……ã€‚å¿…é¡»æ˜¯åŒ…æ‹¬å‘½ä»¤å’Œå‚æ•°çš„å®Œæ•´æç¤ºè¯"""

        # ä»¥ç©ºæ ¼åˆ†å‰²å•è¯
        tokens = prompt.split()
        # ç¬¬ä¸€ä¸ªå•è¯ä½œä¸ºå‘½ä»¤æˆ–å‘½ä»¤åˆ—è¡¨
        cmd_raw = tokens[0]

        # è§£æå¤šè§¦å‘è¯
        if cmd_raw.startswith("[") and cmd_raw.endswith("]"):
            # ç§»é™¤æ‹¬å·å¹¶æŒ‰é€—å·åˆ†å‰²
            cmd_list = cmd_raw[1:-1].split(",")
        else:
            cmd_list = [cmd_raw]

        # è¿­ä»£å™¨è·³è¿‡ç¬¬ä¸€ä¸ªå•è¯
        tokens_iter = iter(tokens[1:])
        # æç¤ºè¯ä¼ é€’å‚æ•°åˆ—è¡¨
        params = {}
        # è¿‡æ»¤åçš„æç¤ºè¯å•è¯åˆ—è¡¨
        filtered = []

        # è§£æå‚æ•°
        while True:
            token = next(tokens_iter, None)
            if token is None:
                break
            if token.startswith("--"):
                key = token[2:]
                # å¤„ç†å‚æ•°åˆ«ç§°æ˜ å°„
                if key in PARAMS_ALIAS_MAP:
                    key = PARAMS_ALIAS_MAP[key]
                # ä»…å¤„ç†å·²çŸ¥å‚æ•°
                if key in PARAMS_LIST:
                    value = next(tokens_iter, None)
                    if value is None:
                        params[key] = True
                        break
                    value = value.strip()
                    if value.startswith("--"):
                        params[key] = True
                        # å°†è¢«æå‰è¿­ä»£çš„å•è¯æ”¾å›è¿­ä»£æµçš„æœ€å‰ç«¯
                        tokens_iter = itertools.chain([value], tokens_iter)
                        continue
                    elif value.lower() == "true":
                        params[key] = True
                    elif value.lower() == "false":
                        params[key] = False
                    # å¤„ç†å­—ç¬¦ä¸²æ•°å­—ç±»å‹
                    elif value.isdigit():
                        params[key] = int(value)
                    else:
                        params[key] = value
                    continue
            filtered.append(token)

        # é‡æ–°ç»„åˆæç¤ºè¯
        prompt = " ".join(filtered)
        params["prompt"] = prompt
        return cmd_list, params

    # === è¾…åŠ©åŠŸèƒ½ï¼šåˆ¤æ–­ç®¡ç†å‘˜ï¼Œç”¨äºé™é»˜è·³å‡º ===
    def is_global_admin(self, event: AstrMessageEvent) -> bool:
        """æ£€æŸ¥å‘é€è€…æ˜¯å¦ä¸ºå…¨å±€ç®¡ç†å‘˜"""
        admin_ids = self.context.get_config().get("admins_id", [])
        # logger.info(f"å…¨å±€ç®¡ç†å‘˜åˆ—è¡¨ï¼š{admin_ids}")
        return event.get_sender_id() in admin_ids

    @filter.command("ä½¿ç”¨æ¨¡å‹åˆ‡æ¢")
    async def switch_provider_model_command(
        self, event: AstrMessageEvent, model_id: str = ""
    ):
        raw = (event.message_str or "").strip()
        if not model_id:
            tokens = raw.split()
            if len(tokens) >= 2:
                model_id = tokens[1].strip()

        model_map = {
            "1": "gemini-3.0-pro-image-portrait",
            "2": "gemini-3.0-pro-image-landscape",
            "3": "nano-banana-pro",
        }
        token = str(model_id).strip()
        key = token[:1] if token else ""
        if key not in model_map:
            m = re.search(r"([123])", token)
            key = m.group(1) if m else ""
        chosen = model_map.get(key)
        if not chosen:
            yield event.plain_result(
                "âŒ ç”¨æ³•ï¼šä½¿ç”¨æ¨¡å‹åˆ‡æ¢ <1/2/3>\n1ï¼šgemini-3.0-pro-image-portrait\n2ï¼šgemini-3.0-pro-image-landscape\n3ï¼šnano-banana-pro"
            )
            return

        self.user_selected_provider_model[event.get_sender_id()] = chosen
        yield event.plain_result(f"âœ… å·²åˆ‡æ¢æ¨¡å‹ï¼š{key}ï¼ˆ{chosen}ï¼‰")

    # === ç®¡ç†æŒ‡ä»¤ï¼šç™½åå•ç®¡ç† ===
    @filter.command("lmç™½åå•æ·»åŠ ", alias={"lmawl"})
    async def add_whitelist_command(
        self, event: AstrMessageEvent, cmd_type: str = "", target_id: str = ""
    ):
        """lmç™½åå•æ·»åŠ  <ç”¨æˆ·/ç¾¤ç»„> <ID>"""
        if not self.is_global_admin(event):
            logger.info(
                f"ç”¨æˆ· {event.get_sender_id()} è¯•å›¾æ‰§è¡Œç®¡ç†å‘˜å‘½ä»¤ lmç™½åå•æ·»åŠ ï¼Œæƒé™ä¸è¶³"
            )
            return

        if not cmd_type or not target_id:
            yield event.plain_result(
                "âŒ æ ¼å¼é”™è¯¯ã€‚\nç”¨æ³•ï¼šlmç™½åå•æ·»åŠ  (ç”¨æˆ·/ç¾¤ç»„) (ID)"
            )
            return

        msg_type = ""
        if cmd_type in ["ç”¨æˆ·", "user"] and target_id not in self.user_whitelist:
            msg_type = "ç”¨æˆ·"
            self.user_whitelist.append(target_id)
        elif cmd_type in ["ç¾¤ç»„", "group"] and target_id not in self.group_whitelist:
            msg_type = "ç¾¤ç»„"
            self.group_whitelist.append(target_id)
        elif cmd_type not in ["ç”¨æˆ·", "user", "ç¾¤ç»„", "group"]:
            yield event.plain_result("âŒ ç±»å‹é”™è¯¯ï¼Œè¯·ä½¿ç”¨ã€Œç”¨æˆ·ã€æˆ–ã€Œç¾¤ç»„ã€ã€‚")
            return
        else:
            yield event.plain_result(f"âš ï¸ {target_id} å·²åœ¨åå•åˆ—è¡¨ä¸­ã€‚")
            return

        yield event.plain_result(f"âœ… å·²æ·»åŠ {msg_type}ç™½åå•ï¼š{target_id}")

    @filter.command("lmç™½åå•åˆ é™¤", alias={"lmdwl"})
    async def del_whitelist_command(
        self, event: AstrMessageEvent, cmd_type: str = "", target_id: str = ""
    ):
        """lmç™½åå•åˆ é™¤ <ç”¨æˆ·/ç¾¤ç»„> <ID>"""
        if not self.is_global_admin(event):
            logger.info(
                f"ç”¨æˆ· {event.get_sender_id()} è¯•å›¾æ‰§è¡Œç®¡ç†å‘˜å‘½ä»¤ lmç™½åå•åˆ é™¤ï¼Œæƒé™ä¸è¶³"
            )
            return

        if not cmd_type or not target_id:
            yield event.plain_result(
                "âŒ æ ¼å¼é”™è¯¯ã€‚\nç”¨æ³•ï¼šlmç™½åå•åˆ é™¤ (ç”¨æˆ·/ç¾¤ç»„) (ID)"
            )
            return

        if cmd_type in ["ç”¨æˆ·", "user"] and target_id in self.user_whitelist:
            msg_type = "ç”¨æˆ·"
            self.user_whitelist.remove(target_id)
        elif cmd_type in ["ç¾¤ç»„", "group"] and target_id in self.group_whitelist:
            msg_type = "ç¾¤ç»„"
            self.group_whitelist.remove(target_id)
        elif cmd_type not in ["ç”¨æˆ·", "user", "ç¾¤ç»„", "group"]:
            yield event.plain_result("âŒ ç±»å‹é”™è¯¯ï¼Œè¯·ä½¿ç”¨ã€Œç”¨æˆ·ã€æˆ–ã€Œç¾¤ç»„ã€ã€‚")
            return
        else:
            yield event.plain_result(f"âš ï¸ {target_id} ä¸åœ¨åå•åˆ—è¡¨ä¸­ã€‚")
            return

        self.conf.save_config()
        yield event.plain_result(f"ğŸ—‘ï¸ å·²åˆ é™¤{msg_type}ç™½åå•ï¼š{target_id}")

    @filter.command("lmç™½åå•åˆ—è¡¨", alias={"lmwll"})
    async def list_whitelist_command(self, event: AstrMessageEvent):
        """lmç™½åå•åˆ—è¡¨"""
        if not self.is_global_admin(event):
            logger.info(
                f"ç”¨æˆ· {event.get_sender_id()} è¯•å›¾æ‰§è¡Œç®¡ç†å‘˜å‘½ä»¤ lmç™½åå•åˆ—è¡¨ï¼Œæƒé™ä¸è¶³"
            )
            return

        msg = f"""ğŸ“‹ ç™½åå•é…ç½®çŠ¶æ€ï¼š
=========
ğŸ¢ ç¾¤ç»„é™åˆ¶ï¼š{"âœ… å¼€å¯" if self.group_whitelist_enabled else "â¬œ å…³é—­"}
åˆ—è¡¨ï¼š{self.group_whitelist}
=========
ğŸ‘¤ ç”¨æˆ·é™åˆ¶ï¼š{"âœ… å¼€å¯" if self.user_whitelist_enabled else "â¬œ å…³é—­"}
åˆ—è¡¨ï¼š{self.user_whitelist}"""

        yield event.plain_result(msg)

    # === ç®¡ç†æŒ‡ä»¤ï¼šæ¨¡å‹ç®¡ç† ===
    @filter.command("lmæ¨¡å‹åˆ—è¡¨", alias={"lmml"})
    async def list_models_command(self, event: AstrMessageEvent):
        """lmæ¨¡å‹åˆ—è¡¨ - æŸ¥çœ‹å½“å‰é…ç½®çš„æ¨¡å‹å’Œæä¾›å•†"""
        if not self.is_global_admin(event):
            return

        msg = ["ğŸ“‹ å½“å‰æ¨¡å‹é…ç½®ï¼š"]
        if not self.models:
            msg.append("æš‚æ— æ¨¡å‹é…ç½®ã€‚")
        
        for i, model in enumerate(self.models):
            msg.append(f"{i+1}. {model.name} [{'âœ…å¯ç”¨' if model.enabled else 'âŒç¦ç”¨'}]")
            msg.append(f"   è§¦å‘è¯: {', '.join(model.triggers)}")
            if not model.providers:
                msg.append("   æä¾›å•†: æ— ")
            else:
                msg.append(f"   æä¾›å•† ({len(model.providers)}):")
                for j, provider in enumerate(model.providers):
                    msg.append(f"     {j+1}. [{provider.api_type}] {provider.name} {'(âœ…)' if provider.enabled else '(âŒ)'}")
        
        yield event.plain_result("\n".join(msg))


    @filter.command("lmè§¦å‘è¯æ·»åŠ ", alias={"lmtka"})
    async def add_model_trigger_command(self, event: AstrMessageEvent, model_name: str = "", trigger: str = ""):
        """lmè§¦å‘è¯æ·»åŠ  <æ¨¡å‹åç§°> <è§¦å‘è¯>"""
        if not self.is_global_admin(event):
            return

        if not model_name or not trigger:
            yield event.plain_result("âŒ ç”¨æ³•ï¼šlmè§¦å‘è¯æ·»åŠ  <æ¨¡å‹åç§°> <è§¦å‘è¯>")
            return

        models_data = self.conf.get("models", [])
        if not isinstance(models_data, list):
            models_data = []

        target_model = None
        for m in models_data:
            if m.get("name") == model_name:
                target_model = m
                break
        
        if not target_model:
            yield event.plain_result(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹ï¼š{model_name}")
            return
        
        current_triggers = target_model.get("triggers", [])
        if trigger in current_triggers:
            yield event.plain_result(f"âš ï¸ è§¦å‘è¯ {trigger} å·²å­˜åœ¨äºæ¨¡å‹ {model_name}ã€‚")
            return
            
        current_triggers.append(trigger)
        target_model["triggers"] = current_triggers

        self.conf["models"] = models_data
        
        self.conf.save_config()
        self.init_providers()
        self.init_prompts()
        
        yield event.plain_result(f"âœ… å·²ä¸ºæ¨¡å‹ {model_name} æ·»åŠ è§¦å‘è¯ï¼š{trigger}")



    @filter.command("lmæä¾›å•†æ·»åŠ ", alias={"lmpa"})
    async def add_provider_command(self, event: AstrMessageEvent, model_name: str = "", api_type: str = ""):
        """lmæä¾›å•†æ·»åŠ  <æ¨¡å‹åç§°> <ç±»å‹: Gemini/OpenAI_Chat>"""
        if not self.is_global_admin(event):
            return

        if not model_name or not api_type:
            yield event.plain_result("âŒ ç”¨æ³•ï¼šlmæä¾›å•†æ·»åŠ  <æ¨¡å‹åç§°> <ç±»å‹>\næ”¯æŒç±»å‹: Gemini, OpenAI_Chat, OpenAI_Images, Vertex_AI_Anonymous")
            return

        # Validate Model
        models_data = self.conf.get("models", [])
        target_model_data = None
        for m in models_data:
            if m.get("name") == model_name:
                target_model_data = m
                break
        
        if not target_model_data:
            yield event.plain_result(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹ï¼š{model_name}")
            return

        # Validate Type
        # Note: Should match _API_Type literal
        valid_types = ["Gemini", "OpenAI_Chat", "OpenAI_Images", "Vertex_AI_Anonymous"]
        # Case insensitive match
        api_type_match = next((t for t in valid_types if t.lower() == api_type.lower()), None)
        
        if not api_type_match:
             yield event.plain_result(f"âŒ ä¸æ”¯æŒçš„ç±»å‹ï¼š{api_type}ã€‚\nå¯é€‰ï¼š{', '.join(valid_types)}")
             return
        
        api_type = api_type_match

        # Prepare default config
        provider_name = f"{api_type}_{len(target_model_data.get('providers', [])) + 1}"
        provider_config = {
            "name": provider_name,
            "enabled": True,
            "api_type": api_type,
            "keys": [],
            "api_url": "",
            "model": "gemini-2.0-flash-exp" if "Gemini" in api_type else "gpt-4o",
            "stream": False
        }
        
        # If Vertex_AI_Anonymous, no key needed
        if api_type == "Vertex_AI_Anonymous":
             if "providers" not in target_model_data:
                target_model_data["providers"] = []
             target_model_data["providers"].append(provider_config)
             self.conf.save_config()
             self.init_providers()
             yield event.plain_result(f"âœ… å·²æ·»åŠ æä¾›å•† {provider_name} åˆ°æ¨¡å‹ {model_name}ã€‚")
             return

        # Interactive Setup
        yield event.plain_result(f"ğŸŒ æ­£åœ¨ä¸ºæ¨¡å‹ {model_name} æ·»åŠ  {api_type} æä¾›å•†ã€‚\nè¯·åœ¨60ç§’å†…è¾“å…¥ API Key (å¦‚æœä¸éœ€è¦è¯·è¾“å…¥ 'none' æˆ– 'skip')ï¼š")
        
        operator_id = event.get_sender_id()
        
        @session_waiter(timeout=60, record_history_chains=False)
        async def waiter(controller: SessionController, ctx: AstrMessageEvent):
            if ctx.get_sender_id() != operator_id:
                return
            
            content = ctx.message_str.strip()
            if content == "å–æ¶ˆ":
                await ctx.send(ctx.plain_result("å·²å–æ¶ˆã€‚"))
                controller.stop()
                return

            if content.lower() not in ["none", "skip", "è·³è¿‡"]:
                provider_config["keys"] = [content]
            
            # Add to config
            if "providers" not in target_model_data:
                target_model_data["providers"] = []
            target_model_data["providers"].append(provider_config)
            
            self.conf.save_config()
            self.init_providers()
            
            await ctx.send(ctx.plain_result(f"âœ… å·²æ·»åŠ æä¾›å•† {provider_name} åˆ°æ¨¡å‹ {model_name}ã€‚\næ›´å¤šå‚æ•°ï¼ˆå¦‚APIåœ°å€ï¼‰è¯·é€šè¿‡é…ç½®æ–‡ä»¶æˆ–WebUIä¿®æ”¹ã€‚"))
            controller.stop()

        try:
            await waiter(event)
        except TimeoutError:
             yield event.plain_result("âŒ è¶…æ—¶ï¼Œæ“ä½œå·²å–æ¶ˆã€‚")

    @filter.command("lmæä¾›å•†åˆ é™¤", alias={"lmpd"})
    async def del_provider_command(self, event: AstrMessageEvent, model_name: str = "", provider_index: str = ""):
        """lmæä¾›å•†åˆ é™¤ <æ¨¡å‹åç§°> <åºå·>"""
        if not self.is_global_admin(event):
            return

        if not model_name or not provider_index or not provider_index.isdigit():
            yield event.plain_result("âŒ ç”¨æ³•ï¼šlmæä¾›å•†åˆ é™¤ <æ¨¡å‹åç§°> <åºå·(ä»1å¼€å§‹)>")
            return
        
        idx = int(provider_index) - 1
        
        models_data = self.conf.get("models", [])
        target_model_data = None
        for m in models_data:
            if m.get("name") == model_name:
                target_model_data = m
                break
        
        if not target_model_data:
            yield event.plain_result(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹ï¼š{model_name}")
            return
            
        providers = target_model_data.get("providers", [])
        if idx < 0 or idx >= len(providers):
             yield event.plain_result(f"âŒ åºå· {provider_index} æ— æ•ˆã€‚å½“å‰æœ‰ {len(providers)} ä¸ªæä¾›å•†ã€‚")
             return
             
        removed = providers.pop(idx)
        target_model_data["providers"] = providers
        
        self.conf.save_config()
        self.init_providers()
        
        yield event.plain_result(f"ğŸ—‘ï¸ å·²ä»æ¨¡å‹ {model_name} åˆ é™¤æä¾›å•†ï¼š{removed.get('name')}")

    # === ç®¡ç†æŒ‡ä»¤ï¼šæ·»åŠ /æ›´æ–°æç¤ºè¯ ===
    @filter.command("lmæ·»åŠ ", alias={"lma"})
    async def add_prompt_command(self, event: AstrMessageEvent, trigger_word: str = ""):
        """lmæ·»åŠ  <è§¦å‘è¯> <æç¤ºè¯å†…å®¹>"""
        if not self.is_global_admin(event):
            logger.info(
                f"ç”¨æˆ· {event.get_sender_id()} è¯•å›¾æ‰§è¡Œç®¡ç†å‘˜å‘½ä»¤ lmæ·»åŠ ï¼Œæƒé™ä¸è¶³"
            )
            return

        if not trigger_word:
            yield event.plain_result("âŒ æ ¼å¼é”™è¯¯ï¼šlmæ·»åŠ  (è§¦å‘è¯)")
            return

        yield event.plain_result(
            f"ğŸŒ æ­£åœ¨ä¸ºè§¦å‘è¯ ã€Œ{trigger_word}ã€ æ·»åŠ /æ›´æ–°æç¤ºè¯\nâœ¦ è¯·åœ¨60ç§’å†…è¾“å…¥å®Œæ•´çš„æç¤ºè¯å†…å®¹ï¼ˆä¸å«è§¦å‘è¯ï¼ŒåŒ…å«å‚æ•°ï¼‰\nâœ¦ è¾“å…¥ã€Œå–æ¶ˆã€å¯å–æ¶ˆæ“ä½œã€‚"
        )

        # è®°å½•æ“ä½œå‘˜è´¦å·
        operator_id = event.get_sender_id()

        @session_waiter(timeout=60, record_history_chains=False)  # type: ignore
        async def waiter(controller: SessionController, event: AstrMessageEvent):
            # åˆ¤æ–­æ¶ˆæ¯æ¥æºæ˜¯å¦æ˜¯åŒä¸€ç”¨æˆ·ï¼ˆåŒä¸€ç”¨æˆ·ä¸éœ€è¦é‰´æƒäº†å§ï¼‰
            if event.get_sender_id() != operator_id:
                return

            if event.message_str.strip() == "å–æ¶ˆ":
                await event.send(event.plain_result("ğŸŒ æ“ä½œå·²å–æ¶ˆã€‚"))
                controller.stop()
                return

            build_prompt = f"{trigger_word} {event.message_str.strip()}"

            action = "æ·»åŠ "
            # ç›´æ¥ä»å­—å…¸ä¸­æŸ¥é‡
            if trigger_word in self.prompt_dict:
                action = "æ›´æ–°"
                # ä»æç¤ºè¯åˆ—è¡¨ä¸­æ‰¾å‡ºå¯¹åº”é¡¹è¿›è¡Œæ›´æ–°
                for i, v in enumerate(self.prompt_list):
                    cmd, _, prompt_str = v.strip().partition(" ")
                    if cmd == trigger_word:
                        self.prompt_list[i] = build_prompt
                        break
                    # å¤„ç†å¤šè§¦å‘è¯
                    if cmd.startswith("[") and cmd.endswith("]"):
                        # ç§»é™¤æ‹¬å·å¹¶æŒ‰é€—å·åˆ†å‰²
                        cmd_list = cmd[1:-1].split(",")
                        if trigger_word in cmd_list:
                            # å°†è¿™ä¸ªæç¤ºè¯ä»å¤šè§¦å‘æç¤ºè¯ä¸­ç§»é™¤
                            cmd_list.remove(trigger_word)
                            # é‡æ–°æ„å»ºæç¤ºè¯å­—ç¬¦ä¸²
                            if len(cmd_list) == 1:
                                # ä»…å‰©ä¸€ä¸ªè§¦å‘è¯ï¼Œæ”¹ä¸ºå•è§¦å‘è¯å½¢å¼
                                new_config_item = f"{cmd_list[0]} {prompt_str}"
                            else:
                                new_cmd = "[" + ",".join(cmd_list) + "]"
                                new_config_item = f"{new_cmd} {prompt_str}"
                            self.prompt_list[i] = new_config_item
                            # æœ€åä¸ºæ–°çš„æç¤ºè¯æ·»åŠ ä¸€é¡¹
                            self.prompt_list.append(build_prompt)
                            break
            # æ–°å¢æç¤ºè¯
            else:
                self.prompt_list.append(build_prompt)

            self.conf.save_config()
            self.init_prompts()
            await event.send(
                event.plain_result(f"âœ… å·²æˆåŠŸ{action}æç¤ºè¯ï¼šã€Œ{trigger_word}ã€")
            )
            controller.stop()

        try:
            await waiter(event)
        except TimeoutError as _:
            yield event.plain_result("âŒ è¶…æ—¶äº†ï¼Œæ“ä½œå·²å–æ¶ˆï¼")
        except Exception as e:
            logger.error(f"å¤§é¦™è•‰æ·»åŠ æç¤ºè¯å‡ºç°é”™è¯¯: {e}", exc_info=True)
            yield event.plain_result("âŒ å¤„ç†æ—¶å‘ç”Ÿäº†ä¸€ä¸ªå†…éƒ¨é”™è¯¯ã€‚")
        finally:
            event.stop_event()

    @filter.command("lmp")
    async def add_prompt_quick_command(
        self, event: AstrMessageEvent, trigger_word: str = "", prompt_str: str = ""
    ):
        """æ·»åŠ æç¤ºè¯é¢„è®¾"""
        if not self.is_global_admin(event):
            logger.info(
                f"ç”¨æˆ· {event.get_sender_id()} è¯•å›¾æ‰§è¡Œç®¡ç†å‘˜å‘½ä»¤ lmpï¼Œæƒé™ä¸è¶³"
            )
            return

        raw = (event.message_str or "").strip()
        if not trigger_word:
            tokens = raw.split()
            if len(tokens) >= 2:
                trigger_word = tokens[1]
            else:
                yield event.plain_result("âŒ ç”¨æ³•ï¼šlmp <è§¦å‘è¯> <æç¤ºè¯å†…å®¹>")
                return

        if raw and trigger_word in raw:
            suffix = raw.split(trigger_word, 1)[1].strip()
            if suffix:
                prompt_str = suffix

        if not prompt_str.strip():
            yield event.plain_result(
                f"ğŸ“ è¯·å‘é€æç¤ºè¯å†…å®¹ï¼ˆç”¨äºè§¦å‘è¯ã€Œ{trigger_word}ã€ï¼‰ï¼Œ30 ç§’å†…æœ‰æ•ˆã€‚"
            )

            @session_waiter(timeout=30, record_history_chains=False)  # type: ignore
            async def waiter(controller: SessionController, event: AstrMessageEvent):
                if not self.is_global_admin(event):
                    logger.info(
                        f"ç”¨æˆ· {event.get_sender_id()} è¯•å›¾æ‰§è¡Œç®¡ç†å‘˜å‘½ä»¤ lmpï¼Œæƒé™ä¸è¶³"
                    )
                    return

                reply = (event.message_str or "").strip()
                if not reply:
                    await event.send(
                        event.plain_result("âŒ æç¤ºè¯å†…å®¹ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°å‘é€ã€‚")
                    )
                    return

                build_prompt = f"{trigger_word} {reply}"
                action = "æ·»åŠ "

                if trigger_word in self.prompt_dict:
                    action = "æ›´æ–°"
                    for i, v in enumerate(self.prompt_list):
                        cmd, _, existing_prompt_str = v.strip().partition(" ")
                        if cmd == trigger_word:
                            self.prompt_list[i] = build_prompt
                            break
                        if cmd.startswith("[") and cmd.endswith("]"):
                            cmd_list = cmd[1:-1].split(",")
                            if trigger_word in cmd_list:
                                cmd_list.remove(trigger_word)
                                if len(cmd_list) == 1:
                                    new_config_item = (
                                        f"{cmd_list[0]} {existing_prompt_str}"
                                    )
                                else:
                                    new_cmd = "[" + ",".join(cmd_list) + "]"
                                    new_config_item = f"{new_cmd} {existing_prompt_str}"
                                self.prompt_list[i] = new_config_item
                                self.prompt_list.append(build_prompt)
                                break
                else:
                    self.prompt_list.append(build_prompt)

                self.conf.save_config()
                self.init_prompts()
                await event.send(
                    event.plain_result(
                        f"âœ… å·²æˆåŠŸ{action}æç¤ºè¯ï¼šã€Œ{trigger_word}ã€"
                    )
                )
                controller.stop()

            try:
                await waiter(event)
            except TimeoutError:
                yield event.plain_result("âŒ è¶…æ—¶äº†ï¼Œæ“ä½œå·²å–æ¶ˆï¼")
            except Exception as e:
                logger.error(f"lmp è¿½åŠ æç¤ºè¯å‡ºç°é”™è¯¯: {e}", exc_info=True)
                yield event.plain_result("âŒ å¤„ç†æ—¶å‘ç”Ÿäº†ä¸€ä¸ªå†…éƒ¨é”™è¯¯ã€‚")
            finally:
                event.stop_event()
            return

        build_prompt = f"{trigger_word} {prompt_str}"
        action = "æ·»åŠ "

        if trigger_word in self.prompt_dict:
            action = "æ›´æ–°"
            for i, v in enumerate(self.prompt_list):
                cmd, _, existing_prompt_str = v.strip().partition(" ")
                if cmd == trigger_word:
                    self.prompt_list[i] = build_prompt
                    break
                if cmd.startswith("[") and cmd.endswith("]"):
                    cmd_list = cmd[1:-1].split(",")
                    if trigger_word in cmd_list:
                        cmd_list.remove(trigger_word)
                        if len(cmd_list) == 1:
                            new_config_item = f"{cmd_list[0]} {existing_prompt_str}"
                        else:
                            new_cmd = "[" + ",".join(cmd_list) + "]"
                            new_config_item = f"{new_cmd} {existing_prompt_str}"
                        self.prompt_list[i] = new_config_item
                        self.prompt_list.append(build_prompt)
                        break
        else:
            self.prompt_list.append(build_prompt)

        self.conf.save_config()
        self.init_prompts()
        yield event.plain_result(f"âœ… å·²æˆåŠŸ{action}æç¤ºè¯ï¼šã€Œ{trigger_word}ã€")

    @filter.command("lmåˆ—è¡¨", alias={"lml", "lmpl"})
    async def list_prompts_command(self, event: AstrMessageEvent):
        """lmåˆ—è¡¨"""
        if not self.is_global_admin(event):
            logger.info(
                f"ç”¨æˆ· {event.get_sender_id()} è¯•å›¾æ‰§è¡Œç®¡ç†å‘˜å‘½ä»¤ lmåˆ—è¡¨ï¼Œæƒé™ä¸è¶³"
            )
            return

        prompts = list(self.prompt_dict.keys())
        if not prompts:
            yield event.plain_result("å½“å‰æ²¡æœ‰é¢„è®¾æç¤ºè¯ã€‚")
            return

        msg = "ğŸ“œ å½“å‰é¢„è®¾æç¤ºè¯åˆ—è¡¨ï¼š\n" + "ã€".join(prompts)
        yield event.plain_result(msg)

    @filter.command("lmæç¤ºè¯", alias={"lmc", "lmè¯¦æƒ…", "lmps"})
    async def prompt_details(self, event: AstrMessageEvent, trigger_word: str):
        """è·å–æç¤ºè¯è¯¦æƒ…å­—ç¬¦ä¸²"""
        if trigger_word not in self.prompt_dict:
            yield event.plain_result(f"âŒ æœªæ‰¾åˆ°æç¤ºè¯ï¼šã€Œ{trigger_word}ã€")
            return

        params = self.prompt_dict[trigger_word]
        details = [f"ğŸ“‹ æç¤ºè¯è¯¦æƒ…ï¼šã€Œ{trigger_word}ã€"]
        details.append(params.get("prompt", ""))
        for key in PARAMS_LIST:
            if key in params:
                details.append(f"{key}: {params[key]}")
        if event.platform_meta.name == "aiocqhttp":
            from astrbot.api.message_components import Node, Nodes, Plain

            nodes = []
            for detail in details:
                nodes.append(
                    Node(
                        uin=event.get_sender_id(),
                        name=event.get_sender_name(),
                        content=[Plain(detail)],
                    )
                )
            yield event.chain_result([Nodes(nodes)])
        else:
            yield event.plain_result("\n".join(details))

    @filter.command("lmåˆ é™¤", alias={"lmd"})
    async def del_prompt_command(self, event: AstrMessageEvent, trigger_word: str = ""):
        """lmåˆ é™¤ <è§¦å‘è¯>"""
        if not self.is_global_admin(event):
            logger.info(
                f"ç”¨æˆ· {event.get_sender_id()} è¯•å›¾æ‰§è¡Œç®¡ç†å‘˜å‘½ä»¤ lmåˆ é™¤ï¼Œæƒé™ä¸è¶³"
            )
            return

        if not trigger_word:
            yield event.plain_result("âŒ æ ¼å¼é”™è¯¯ï¼šlmåˆ é™¤ (è§¦å‘è¯)")
            return

        if trigger_word not in self.prompt_dict:
            yield event.plain_result(f"âŒ æœªæ‰¾åˆ°æç¤ºè¯ï¼šã€Œ{trigger_word}ã€")
            return

        # ä»æç¤ºè¯åˆ—è¡¨ä¸­æ‰¾å‡ºå¯¹åº”é¡¹è¿›è¡Œæ›´æ–°
        for i, v in enumerate(self.prompt_list):
            cmd, _, prompt_str = v.strip().partition(" ")
            if cmd == trigger_word:
                del self.prompt_list[i]
                self.init_prompts()
                self.conf.save_config()
                yield event.plain_result(f"ğŸ—‘ï¸ å·²åˆ é™¤æç¤ºè¯ï¼šã€Œ{trigger_word}ã€")
                return
            # å¤„ç†å¤šè§¦å‘è¯
            if cmd.startswith("[") and cmd.endswith("]"):
                # ç§»é™¤æ‹¬å·å¹¶æŒ‰é€—å·åˆ†å‰²
                cmd_list = cmd[1:-1].split(",")
                if trigger_word not in cmd_list:
                    continue

                yield event.plain_result(
                    "âš ï¸ æ£€æµ‹åˆ°è¯¥æç¤ºè¯ä¸ºå¤šè§¦å‘è¯é…ç½®ï¼Œè¯·é€‰æ‹©åˆ é™¤æ–¹æ¡ˆ\nA. å•ç‹¬åˆ é™¤è¯¥è§¦å‘è¯\nB. åˆ é™¤è¯¥å¤šè§¦å‘è¯\nC. å–æ¶ˆæ“ä½œ"
                )

                # åˆ é™¤å¤šè§¦å‘è¯æ—¶ï¼Œè¿›è¡ŒäºŒæ¬¡ç¡®è®¤
                @session_waiter(timeout=30, record_history_chains=False)  # type: ignore
                async def waiter(
                    controller: SessionController, event: AstrMessageEvent
                ):
                    # å…ˆé‰´æƒ
                    if not self.is_global_admin(event):
                        logger.info(
                            f"ç”¨æˆ· {event.get_sender_id()} è¯•å›¾æ‰§è¡Œç®¡ç†å‘˜å‘½ä»¤ lmåˆ é™¤ï¼Œæƒé™ä¸è¶³"
                        )
                        return

                    # è·å–ç”¨æˆ·å›å¤å†…å®¹
                    reply_content = event.message_str.strip().upper()
                    if reply_content not in ["A", "B", "C"]:
                        await event.send(
                            event.plain_result("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„é€‰é¡¹ï¼šAã€B æˆ– Cã€‚")
                        )
                        return

                    if reply_content == "C":
                        await event.send(event.plain_result("ğŸŒ æ“ä½œå·²å–æ¶ˆã€‚"))
                        controller.stop()
                        return
                    if reply_content == "B":
                        # åˆ é™¤æ•´ä¸ªå¤šè§¦å‘è¯é…ç½®
                        del self.prompt_list[i]
                        await event.send(
                            event.plain_result(f"ğŸ—‘ï¸ å·²åˆ é™¤å¤šè§¦å‘æç¤ºè¯ï¼š{cmd}")
                        )
                        self.conf.save_config()
                        controller.stop()
                        return
                    if reply_content == "A":
                        # å°†è¿™ä¸ªæç¤ºè¯ä»å¤šè§¦å‘æç¤ºè¯ä¸­ç§»é™¤
                        cmd_list.remove(trigger_word)
                        # é‡æ–°æ„å»ºæç¤ºè¯å­—ç¬¦ä¸²
                        if len(cmd_list) == 1:
                            # ä»…å‰©ä¸€ä¸ªè§¦å‘è¯ï¼Œæ”¹ä¸ºå•è§¦å‘è¯å½¢å¼
                            new_config_item = f"{cmd_list[0]} {prompt_str}"
                        else:
                            new_cmd = "[" + ",".join(cmd_list) + "]"
                            new_config_item = f"{new_cmd} {prompt_str}"
                        self.prompt_list[i] = new_config_item
                        # æœ€åæ›´æ–°å­—å…¸
                        del self.prompt_dict[trigger_word]
                        # æ›´æ–°å†…å­˜å­—å…¸
                        self.init_prompts()
                        await event.send(
                            event.plain_result(
                                f"ğŸ—‘ï¸ å·²ä»å¤šè§¦å‘æç¤ºè¯ä¸­ç§»é™¤ï¼šã€Œ{trigger_word}ã€"
                            )
                        )
                        self.conf.save_config()
                        controller.stop()
                        return

                try:
                    await waiter(event)
                except TimeoutError as _:
                    yield event.plain_result("âŒ è¶…æ—¶äº†ï¼Œæ“ä½œå·²å–æ¶ˆï¼")
                except Exception as e:
                    logger.error(f"å¤§é¦™è•‰åˆ é™¤æç¤ºè¯å‡ºç°é”™è¯¯: {e}", exc_info=True)
                    yield event.plain_result("âŒ å¤„ç†æ—¶å‘ç”Ÿäº†ä¸€ä¸ªå†…éƒ¨é”™è¯¯ã€‚")
                finally:
                    event.stop_event()
        else:
            logger.error(
                f"æç¤ºè¯åˆ—è¡¨å’Œæç¤ºè¯å­—å…¸ä¸ä¸€è‡´ï¼Œæœªæ‰¾åˆ°æç¤ºè¯ï¼šã€Œ{trigger_word}ã€"
            )
            yield event.plain_result(f"âŒ æœªæ‰¾åˆ°æç¤ºè¯ï¼šã€Œ{trigger_word}ã€")

    @filter.event_message_type(filter.EventMessageType.ALL, priority=5)
    async def on_message(self, event: AstrMessageEvent):
        """ç»˜å›¾å‘½ä»¤æ¶ˆæ¯å…¥å£"""

        # å–å‡ºæ‰€æœ‰ Plain ç±»å‹çš„ç»„ä»¶æ‹¼æ¥æˆçº¯æ–‡æœ¬å†…å®¹
        plain_components = [
            comp for comp in event.get_messages() if isinstance(comp, Comp.Plain)
        ]

        # æ‹¼æ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²
        if plain_components:
            message_str = " ".join(comp.text for comp in plain_components).strip()
        else:
            message_str = event.message_str
        # è·³è¿‡ç©ºæ¶ˆæ¯
        if not message_str:
            return

        # å…ˆå¤„ç†å‰ç¼€
        matched_prefix = False
        for prefix in self.prefix_list:
            if message_str.startswith(prefix):
                message_str = message_str.removeprefix(prefix).lstrip()
                matched_prefix = True
                break

        # è‹¥æœª@æœºå™¨äººä¸”æœªå¼€å¯æ··åˆæ¨¡å¼ï¼Œä¸”é…ç½®äº†å‰ç¼€åˆ—è¡¨ä½†æ¶ˆæ¯æœªåŒ¹é…åˆ°ä»»ä½•å‰ç¼€ï¼Œåˆ™è·³è¿‡å¤„ç†
        if (
            not event.is_at_or_wake_command
            and not self.coexist_enabled
            and self.prefix_list
            and not matched_prefix
        ):
            return

        cmd = message_str.split(" ", 1)[0]
        # æ£€æŸ¥å‘½ä»¤æ˜¯å¦åœ¨æç¤ºè¯é…ç½®ä¸­
        if cmd not in self.prompt_dict:
            return

        # ç¾¤ç™½åå•åˆ¤æ–­
        if (
            self.group_whitelist_enabled
            and event.unified_msg_origin not in self.group_whitelist
        ):
            logger.info(f"ç¾¤ {event.unified_msg_origin} ä¸åœ¨ç™½åå•å†…ï¼Œè·³è¿‡å¤„ç†")
            return

        # ç”¨æˆ·ç™½åå•åˆ¤æ–­
        if (
            self.user_whitelist_enabled
            and event.get_sender_id() not in self.user_whitelist
        ):
            logger.info(f"ç”¨æˆ· {event.get_sender_id()} ä¸åœ¨ç™½åå•å†…ï¼Œè·³è¿‡å¤„ç†")
            return

        # è·å–æç¤ºè¯é…ç½® (ä½¿ç”¨ .copy() é˜²æ­¢ä¿®æ”¹æ±¡æŸ“å…¨å±€é¢„è®¾)
        params = self.prompt_dict.get(cmd, {}).copy()
        params["__trigger_cmd__"] = cmd
        # å…ˆä»é¢„è®¾æç¤ºè¯å‚æ•°å­—å…¸å­—å…¸ä¸­å–å‡ºæç¤ºè¯
        preset_prompt = params.get("prompt", "{{user_text}}")

        _, user_params = self.parsing_prompt_params(message_str)
        user_overrode_min_images = "min_images" in user_params
        user_overrode_model = "model" in user_params
        params["__user_overrode_model__"] = user_overrode_model
        preset_name = user_params.pop("preset", None)
        user_prompt = user_params.get("prompt", "anything").strip()

        if preset_name:
            preset_key = str(preset_name).strip().strip(",ï¼Œ")
            preset_params = self.prompt_dict.get(preset_key, None)
            if not preset_params and preset_key:
                for k, v in self.prompt_dict.items():
                    if isinstance(k, str) and k.strip().strip(",ï¼Œ") == preset_key:
                        preset_params = v
                        break
            if not preset_params:
                yield event.plain_result(f"âŒ æœªæ‰¾åˆ°é¢„è®¾æç¤ºè¯ï¼šã€Œ{preset_name}ã€")
                return

            selected_params = preset_params.copy()
            selected_prompt = selected_params.get("prompt", "{{user_text}}")

            if (
                selected_params.get("preset_append", self.common_config.preset_append)
                and "{{user_text}}" not in selected_prompt
            ):
                selected_prompt += " {{user_text}}"

            if "{{user_text}}" in selected_prompt:
                final_prompt = selected_prompt.replace("{{user_text}}", user_prompt)
            else:
                final_prompt = selected_prompt

            selected_params.pop("prompt", None)
            if "__model_name__" in params:
                selected_params.pop("__model_name__", None)
            params.update(selected_params)
            params.update({k: v for k, v in user_params.items() if k != "prompt"})
            params["prompt"] = final_prompt
        else:
            params.update({k: v for k, v in user_params.items() if k != "prompt"})

        if not user_overrode_model:
            selected_model = self.user_selected_provider_model.get(event.get_sender_id())
            if selected_model and (preset_name is not None or "__model_name__" not in params):
                params.setdefault("model", selected_model)

        # å¤„ç†é¢„è®¾æç¤ºè¯è¡¥å……å‚æ•°preset_append
        if (
            params.get("preset_append", self.common_config.preset_append)
            and "{{user_text}}" not in preset_prompt
        ):
            preset_prompt += " {{user_text}}"

        # æ£€æŸ¥é¢„è®¾æç¤ºè¯ä¸­æ˜¯å¦åŒ…å«åŠ¨æ€å‚æ•°å ä½ç¬¦
        if not preset_name and "{{user_text}}" in preset_prompt:
            new_prompt = preset_prompt.replace("{{user_text}}", user_prompt)
            params["prompt"] = new_prompt

        if cmd in {"iv1", "iv2"} and not user_overrode_min_images:
            params["min_images"] = 2

        is_nanobanana = params.get("__model_name__") == "nano-banana" or cmd in {
            "bnn",
            "bnt",
            "bna",
        }
        if is_nanobanana:
            if (
                self.nanobanana_group_whitelist_enabled
                and event.unified_msg_origin not in self.nanobanana_group_whitelist
            ):
                logger.info(
                    f"ç¾¤ {event.unified_msg_origin} ä¸åœ¨ nano-banana ç™½åå•å†…ï¼Œè·³è¿‡å¤„ç†"
                )
                return
            if (
                self.nanobanana_user_whitelist_enabled
                and event.get_sender_id() not in self.nanobanana_user_whitelist
            ):
                logger.info(
                    f"ç”¨æˆ· {event.get_sender_id()} ä¸åœ¨ nano-banana ç™½åå•å†…ï¼Œè·³è¿‡å¤„ç†"
                )
                return

        if cmd == "åæ¨":
            min_required_images = params.get("min_images", self.prompt_config.min_images)
            try:
                min_required_images = int(min_required_images)
            except Exception:
                min_required_images = 1

            content = await self._image_to_prompt(
                event=event,
                prompt=str(params.get("prompt", "è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡")),
                min_required_images=min_required_images,
            )
            yield event.chain_result(
                [
                    Comp.Reply(id=event.message_obj.message_id),
                    Comp.Plain(content),
                ]
            )
            return

        # å¤„ç†æ”¶é›†æ¨¡å¼
        image_urls = []
        if params.get("gather_mode", self.prompt_config.gather_mode):
            # è®°å½•æ“ä½œå‘˜è´¦å·
            operator_id = event.get_sender_id()
            # å–æ¶ˆæ ‡è®°
            is_cancel = False
            yield event.plain_result(f"""ğŸ“ ç»˜å›¾æ”¶é›†æ¨¡å¼å·²å¯ç”¨ï¼š
æ–‡æœ¬ï¼š{params["prompt"]}
å›¾ç‰‡ï¼š{len(image_urls)} å¼ 

ğŸ’¡ ç»§ç»­å‘é€å›¾ç‰‡æˆ–æ–‡æœ¬ï¼Œæˆ–è€…ï¼š
â€¢ å‘é€ã€Œå¼€å§‹ã€å¼€å§‹ç”Ÿæˆ
â€¢ å‘é€ã€Œå–æ¶ˆã€å–æ¶ˆæ“ä½œ
â€¢ 60 ç§’å†…æœ‰æ•ˆ
""")

            @session_waiter(timeout=60, record_history_chains=False)  # type: ignore
            async def waiter(controller: SessionController, event: AstrMessageEvent):
                nonlocal is_cancel
                # åˆ¤æ–­æ¶ˆæ¯æ¥æºæ˜¯å¦æ˜¯åŒä¸€ç”¨æˆ·
                if event.get_sender_id() != operator_id:
                    return

                if event.message_str.strip() == "å–æ¶ˆ":
                    is_cancel = True
                    await event.send(event.plain_result("âœ… æ“ä½œå·²å–æ¶ˆã€‚"))
                    controller.stop()
                    return
                if event.message_str.strip() == "å¼€å§‹":
                    controller.stop()
                    return
                # å¼€å§‹æ”¶é›†æ–‡æœ¬å’Œå›¾ç‰‡
                for comp in event.get_messages():
                    if isinstance(comp, Comp.Plain) and comp.text:
                        # è¿½åŠ æ–‡æœ¬åˆ°æç¤ºè¯
                        params["prompt"] += " " + comp.text.strip()
                    elif isinstance(comp, Comp.Image) and comp.url:
                        image_urls.append(comp.url)
                    elif (
                        isinstance(comp, Comp.File)
                        and comp.url
                        and comp.url.startswith("http")
                        and comp.url.lower().endswith(SUPPORTED_FILE_FORMATS)
                    ):
                        image_urls.append(comp.url)
                await event.send(
                    event.plain_result(f"""ğŸ“ ç»˜å›¾è¿½åŠ æ¨¡å¼å·²æ”¶é›†å†…å®¹ï¼š
æ–‡æœ¬ï¼š{params["prompt"]}
å›¾ç‰‡ï¼š{len(image_urls)} å¼ 

ğŸ’¡ ç»§ç»­å‘é€å›¾ç‰‡æˆ–æ–‡æœ¬ï¼Œæˆ–è€…ï¼š
â€¢ å‘é€ã€Œå¼€å§‹ã€å¼€å§‹ç”Ÿæˆ
â€¢ å‘é€ã€Œå–æ¶ˆã€å–æ¶ˆæ“ä½œ
â€¢ 60 ç§’å†…æœ‰æ•ˆ
""")
                )
                controller.keep(timeout=60, reset_timeout=True)

            try:
                await waiter(event)
            except TimeoutError as _:
                yield event.plain_result("âŒ è¶…æ—¶äº†ï¼Œæ“ä½œå·²å–æ¶ˆï¼")
                return
            except Exception as e:
                logger.error(f"ç»˜å›¾æç¤ºè¯è¿½åŠ æ¨¡å¼å‡ºç°é”™è¯¯: {e}", exc_info=True)
                yield event.plain_result("âŒ å¤„ç†æ—¶å‘ç”Ÿäº†ä¸€ä¸ªå†…éƒ¨é”™è¯¯ã€‚")
                return
            finally:
                if is_cancel:
                    event.stop_event()
                    return

        logger.info(f"æ­£åœ¨ç”Ÿæˆå›¾ç‰‡ï¼Œæç¤ºè¯: {params['prompt'][:60]}")
        logger.debug(
            f"ç”Ÿæˆå›¾ç‰‡åº”ç”¨å‚æ•°: { {k: v for k, v in params.items() if k != 'prompt'} }"
        )
        task = asyncio.create_task(
            self._run_job_with_limit(event, params, image_urls=image_urls)
        )
        task_id = event.message_obj.message_id
        self.running_tasks[task_id] = task
        task_temp_dir = self.temp_dir / str(task_id)
        os.makedirs(task_temp_dir, exist_ok=True)

        try:
            results, err_msg = await task
            if not results or err_msg:
                if isinstance(err_msg, str) and err_msg.strip().startswith("å›¾ç‰‡ç”Ÿæˆå¤±è´¥"):
                    err_text = err_msg.strip()
                else:
                    err_text = f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼š{err_msg}"
                yield event.chain_result(
                    [
                        Comp.Reply(id=event.message_obj.message_id),
                        Comp.Plain(f"âŒ {err_text}"),
                    ]
                )
                return

            # ç»„è£…æ¶ˆæ¯é“¾
            os.makedirs(task_temp_dir, exist_ok=True)
            msg_chain = self.build_message_chain(event, results, task_temp_dir)

            yield event.chain_result(msg_chain)
        except asyncio.CancelledError:
            logger.info(f"{task_id} ä»»åŠ¡è¢«å–æ¶ˆ")
            return
        finally:
            self.running_tasks.pop(task_id, None)
            clear_cache(task_temp_dir)

    async def job(
        self,
        event: AstrMessageEvent,
        params: dict,
        image_urls: list[str] | None = None,
        referer_id: list[str] | None = None,
        is_llm_tool: bool = False,
    ) -> tuple[list[tuple[str, str]] | None, str | None]:
        """è´Ÿè´£å‚æ•°å¤„ç†ã€è°ƒåº¦æä¾›å•†ã€ä¿å­˜å›¾ç‰‡ç­‰é€»è¾‘ï¼Œè¿”å›å›¾ç‰‡b64åˆ—è¡¨æˆ–é”™è¯¯ä¿¡æ¯"""
        # æ”¶é›†å›¾ç‰‡URLï¼Œåé¢ç»Ÿä¸€å¤„ç†
        if image_urls is None:
            image_urls = []

        if referer_id is None:
            referer_id = []
        # å°æ ‡è®°ï¼Œç”¨äºä¼˜åŒ–Atå¤´åƒã€‚å½“Atå¯¹è±¡æ˜¯è¢«å¼•ç”¨æ¶ˆæ¯çš„å‘é€è€…æ—¶ï¼Œè·³è¿‡ä¸€æ¬¡ã€‚
        skipped_at_qq = False
        reply_sender_id = ""
        for comp in event.get_messages():
            if isinstance(comp, Comp.Reply):
                reply_urls, reply_sender_id = await self._collect_reply_image_urls(event, comp)
                if reply_urls:
                    image_urls.extend(reply_urls)
            # å¤„ç†Atå¯¹è±¡çš„QQå¤´åƒï¼ˆå¯¹äºè‰¾ç‰¹æœºå™¨äººçš„é—®é¢˜ï¼Œè¿˜æ²¡æœ‰ç‰¹åˆ«å¥½çš„è§£å†³æ–¹æ¡ˆï¼‰
            elif (
                isinstance(comp, Comp.At)
                and comp.qq
                and event.platform_meta.name == "aiocqhttp"
            ):
                qq = str(comp.qq)
                self_id = event.get_self_id()
                if not skipped_at_qq and (
                    # å¦‚æœAtå¯¹è±¡æ˜¯è¢«å¼•ç”¨æ¶ˆæ¯çš„å‘é€è€…ï¼Œè·³è¿‡ä¸€æ¬¡
                    (qq == reply_sender_id and self.preference_config.skip_quote_first)
                    or (
                        qq == self_id
                        and event.is_at_or_wake_command
                        and self.preference_config.skip_at_first
                    )  # é€šè¿‡Atå”¤é†’æœºå™¨äººï¼Œè·³è¿‡ä¸€æ¬¡
                    or (
                        qq == self_id
                        and self.preference_config.skip_llm_at_first
                        and is_llm_tool
                    )  # é€šè¿‡Atå”¤é†’æœºå™¨äººï¼Œä¸”æ˜¯å‡½æ•°è°ƒç”¨å·¥å…·ï¼Œè·³è¿‡ä¸€æ¬¡
                ):
                    skipped_at_qq = True
                    continue
                image_urls.append(f"https://q.qlogo.cn/g?b=qq&s=0&nk={comp.qq}")
            elif isinstance(comp, Comp.Image) and comp.url:
                image_urls.append(comp.url)
            elif (
                isinstance(comp, Comp.File)
                and comp.url
                and comp.url.startswith("http")
                and comp.url.lower().endswith(SUPPORTED_FILE_FORMATS)
            ):
                image_urls.append(comp.url)

        q_value = params.get("q")
        if q_value and event.platform_meta.name == "aiocqhttp":
            for qq in re.findall(r"\d+", str(q_value)):
                build_url = f"https://q.qlogo.cn/g?b=qq&s=0&nk={qq}"
                if build_url not in image_urls:
                    image_urls.append(build_url)

        # å¤„ç†referer_idå‚æ•°ï¼Œè·å–æŒ‡å®šç”¨æˆ·å¤´åƒ
        if is_llm_tool and referer_id and event.platform_meta.name == "aiocqhttp":
            for target_id in referer_id:
                target_id = target_id.strip()
                if target_id:
                    build_url = f"https://q.qlogo.cn/g?b=qq&s=0&nk={target_id}"
                    if build_url not in image_urls:
                        image_urls.append(
                            f"https://q.qlogo.cn/g?b=qq&s=0&nk={target_id}"
                        )

        trigger_cmd = str(params.get("__trigger_cmd__") or "").strip()
        is_i2i_mode = trigger_cmd in {"bp1", "bp2", "edit"}
        if (
            is_i2i_mode
            and not image_urls
            and not params.get("refer_images")
            and event.platform_meta.name == "aiocqhttp"
        ):
            image_urls.append(
                f"https://q.qlogo.cn/g?b=qq&s=0&nk={event.get_sender_id()}"
            )

        min_required_images = params.get("min_images", self.prompt_config.min_images)
        max_allowed_images = params.get("max_images", self.prompt_config.max_images)
        # å¦‚æœå›¾ç‰‡æ•°é‡ä¸æ»¡è¶³æœ€å°è¦æ±‚ï¼Œä¸”æ¶ˆæ¯å¹³å°æ˜¯Aiocqhttpï¼Œå–æ¶ˆæ¯å‘é€è€…å¤´åƒä½œä¸ºå‚è€ƒå›¾ç‰‡
        if (
            len(image_urls) < min_required_images
            and int(min_required_images or 0) == 1
            and event.platform_meta.name == "aiocqhttp"
        ):
            image_urls.append(
                f"https://q.qlogo.cn/g?b=qq&s=0&nk={event.get_sender_id()}"
            )

        # å›¾ç‰‡b64åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ (mime_type, b64_data) å…ƒç»„
        image_b64_list = []
        # å¤„ç† refer_images å‚æ•°
        refer_images = params.get("refer_images", self.prompt_config.refer_images)
        if refer_images:
            for filename in refer_images.split(","):
                if len(image_b64_list) >= max_allowed_images:
                    break
                filename = filename.strip()
                if filename:
                    path = self.refer_images_dir / filename
                    mime_type, b64_data = await asyncio.to_thread(read_file, path)
                    if b64_data:
                        image_b64_list.append((mime_type, b64_data))
        # å›¾ç‰‡å»é‡
        image_urls = list(dict.fromkeys(image_urls))
        # åˆ¤æ–­å›¾ç‰‡æ•°é‡æ˜¯å¦æ»¡è¶³æœ€å°è¦æ±‚
        if len(image_urls) + len(image_b64_list) < min_required_images:
            warn_msg = f"å›¾ç‰‡æ•°é‡ä¸è¶³ï¼Œæœ€å°‘éœ€è¦ {min_required_images} å¼ å›¾ç‰‡ï¼Œå½“å‰ä»… {len(image_urls) + len(image_b64_list)} å¼ "
            logger.warning(warn_msg)
            return None, warn_msg

        # æ£€æŸ¥å›¾ç‰‡æ•°é‡æ˜¯å¦è¶…è¿‡æœ€å¤§å…è®¸æ•°é‡ï¼Œä¸è¶…è¿‡åˆ™å¯ä»urlä¸­ä¸‹è½½å›¾ç‰‡
        append_count = max_allowed_images - len(image_b64_list)
        if append_count > 0 and image_urls:
            # å–å‰nå¼ å›¾ç‰‡ï¼Œä¸‹è½½å¹¶è½¬æ¢ä¸ºBase64ï¼Œè¿½åŠ åˆ°b64å›¾ç‰‡åˆ—è¡¨
            if len(image_b64_list) + len(image_urls) > max_allowed_images:
                logger.warning(
                    f"å‚è€ƒå›¾ç‰‡æ•°é‡è¶…è¿‡æˆ–ç­‰äºæœ€å¤§å›¾ç‰‡æ•°é‡ï¼Œå°†åªä½¿ç”¨å‰ {max_allowed_images} å¼ å‚è€ƒå›¾ç‰‡"
                )
            fetched = await self.downloader.fetch_images(image_urls[:append_count])
            if fetched:
                image_b64_list.extend(fetched)

            # å¦‚æœ min_required_images ä¸º 0ï¼Œåˆ—è¡¨ä¸ºç©ºæ˜¯å…è®¸çš„
            if not image_b64_list and min_required_images > 0:
                logger.error("å…¨éƒ¨å‚è€ƒå›¾ç‰‡ä¸‹è½½å¤±è´¥")
                return None, "å…¨éƒ¨å‚è€ƒå›¾ç‰‡ä¸‹è½½å¤±è´¥"

        # å‘é€ç»˜å›¾ä¸­æç¤º
        await event.send(MessageChain().message("ğŸ¨ åœ¨ç”»äº†ï¼Œè¯·ç¨ç­‰ä¸€ä¼š..."))

        # è°ƒåº¦æä¾›å•†ç”Ÿæˆå›¾ç‰‡
        images_result, err = await self._dispatch(
            params=params, image_b64_list=image_b64_list
        )

        # å†æ¬¡æ£€æŸ¥å›¾ç‰‡ç»“æœæ˜¯å¦ä¸ºç©º
        valid_results = [(mime, b64) for mime, b64 in (images_result or []) if b64]

        if not valid_results:
            if not err:
                err = "å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼šå“åº”ä¸­æœªåŒ…å«å›¾ç‰‡æ•°æ®"
                logger.error(err)
            return None, err

        # ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°
        if self.save_images:
            save_images(valid_results, self.save_dir)

        return valid_results, None

    async def _run_job_with_limit(
        self,
        event: AstrMessageEvent,
        params: dict,
        image_urls: list[str] | None = None,
        referer_id: list[str] | None = None,
        is_llm_tool: bool = False,
    ) -> tuple[list[tuple[str, str]] | None, str | None]:
        if self.is_global_admin(event):
            return await self.job(
                event=event,
                params=params,
                image_urls=image_urls,
                referer_id=referer_id,
                is_llm_tool=is_llm_tool,
            )

        sem = self.job_semaphore
        if sem is None:
            return await self.job(
                event=event,
                params=params,
                image_urls=image_urls,
                referer_id=referer_id,
                is_llm_tool=is_llm_tool,
            )

        await sem.acquire()
        try:
            return await self.job(
                event=event,
                params=params,
                image_urls=image_urls,
                referer_id=referer_id,
                is_llm_tool=is_llm_tool,
            )
        finally:
            sem.release()

    async def _dispatch(
        self,
        params: dict,
        image_b64_list: list[tuple[str, str]] = [],
        allow_fallback: bool = True,
    ) -> tuple[list[tuple[str, str]] | None, str | None]:
        """æä¾›å•†è°ƒåº¦å™¨"""
        err = None
        
        # 1. ç¡®å®šä½¿ç”¨çš„æ¨¡å‹
        model_name = params.get("__model_name__")
        target_model = None
        requested_provider_model = (params.get("model") or "").strip()
        
        if model_name:
            for model in self.models:
                if model.name == model_name:
                    target_model = model
                    break
        
        # å¦‚æœæœªæ‰¾åˆ°æŒ‡å®šæ¨¡å‹ï¼ˆæˆ–æœªæŒ‡å®šï¼‰ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ¨¡å‹ä½œä¸ºé»˜è®¤
        if not target_model and self.models:
            if requested_provider_model:
                for model in self.models:
                    if any(
                        (p.model or "").strip() == requested_provider_model
                        for p in model.providers
                    ):
                        target_model = model
                        break
            if not target_model:
                preferred_provider_model = "gemini-3.0-pro-image-portrait"
                for model in self.models:
                    if any(
                        (p.model or "").strip() == preferred_provider_model
                        for p in model.providers
                    ):
                        target_model = model
                        break
            if not target_model:
                target_model = self.models[0]
            
        if not target_model:
            return None, "æœªé…ç½®ä»»ä½•æ¨¡å‹ã€‚"

        # 2. è·å–è¯¥æ¨¡å‹çš„æä¾›å•†åˆ—è¡¨
        all_candidate_providers = target_model.providers
        candidate_providers = all_candidate_providers
        
        # 3. ç­›é€‰æä¾›å•† (å¦‚æœ params æŒ‡å®šäº† provider)
        target_provider_name = params.get("provider")
        
        filtered_by_model_applied = False
        if requested_provider_model and not target_provider_name:
            filtered_by_model = [
                p
                for p in candidate_providers
                if (p.model or "").strip() == requested_provider_model
            ]
            if filtered_by_model:
                candidate_providers = filtered_by_model
                filtered_by_model_applied = True

        if target_provider_name:
            # å°è¯•åŒ¹é… name
            filtered = [
                p for p in candidate_providers 
                if p.name == target_provider_name
            ]
            
            if filtered:
                candidate_providers = filtered
            else:
                logger.warning(f"åœ¨æ¨¡å‹ {target_model.name} ä¸­æœªæ‰¾åˆ°æŒ‡å®šæä¾›å•†: {target_provider_name}ï¼Œå°†ä½¿ç”¨é»˜è®¤é¡ºåº")

        if not candidate_providers:
             return None, f"æ¨¡å‹ {target_model.name} æœªé…ç½®æœ‰æ•ˆçš„æä¾›å•†ã€‚"

        # è°ƒåº¦æä¾›å•†
        for i, provider in enumerate(candidate_providers):
            if provider.api_type not in self.provider_map:
                logger.warning(f"æä¾›å•†ç±»å‹ {provider.api_type} æœªåˆå§‹åŒ–ï¼Œè·³è¿‡")
                continue
                
            images_result, err = await self.provider_map[
                provider.api_type
            ].generate_images(
                provider_config=provider,
                params=params,
                image_b64_list=image_b64_list,
            )
            if images_result:
                logger.info(f"æ¨¡å‹ {target_model.name} - {provider.name} å›¾ç‰‡ç”ŸæˆæˆåŠŸ")
                return images_result, None
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªæä¾›å•†ï¼Œä¸”é…ç½®äº†é‡è¯•é€»è¾‘ï¼ˆéšå«åœ¨åˆ—è¡¨é¡ºåºä¸­ï¼‰ï¼Œåˆ™ç»§ç»­
            if i < len(candidate_providers) - 1:
                logger.warning(f"{provider.name} ç”Ÿæˆå›¾ç‰‡å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ä¸‹ä¸€ä¸ªæä¾›å•†...")

        if (
            allow_fallback
            and filtered_by_model_applied
            and not params.get("__user_overrode_model__", False)
        ):
            remaining = [p for p in all_candidate_providers if p not in candidate_providers]
            if remaining:
                fallback_params = params.copy()
                fallback_params.pop("model", None)
                fallback_params.pop("__user_overrode_model__", None)
                for i, provider in enumerate(remaining):
                    if provider.api_type not in self.provider_map:
                        continue
                    images_result, err = await self.provider_map[
                        provider.api_type
                    ].generate_images(
                        provider_config=provider,
                        params=fallback_params,
                        image_b64_list=image_b64_list,
                    )
                    if images_result:
                        logger.info(f"æ¨¡å‹ {target_model.name} - {provider.name} å›¾ç‰‡ç”ŸæˆæˆåŠŸ")
                        return images_result, None

        if allow_fallback:
            fallback_probe_model = (params.get("model") or candidate_providers[0].model or "").strip()
            is_video_model = fallback_probe_model.startswith("veo_")
            is_flow2api = any((p.name or "").strip() == "flow2api" for p in candidate_providers)
            html_like_error = isinstance(err, str) and (
                "HTML" in err
                or "å“åº”å†…å®¹æ ¼å¼é”™è¯¯" in err
                or "åª’ä½“ä¸‹è½½å¤±è´¥" in err
                or "API åœ°å€ä¸å­˜åœ¨" in err
                or "çŠ¶æ€ç  401" in err
                or "çŠ¶æ€ç  403" in err
                or "çŠ¶æ€ç  404" in err
            )
            if is_flow2api and not is_video_model and html_like_error:
                fallback_model = next(
                    (m for m in self.models if m.enabled and m.name in {"nano-banana", "Z-Image-Turbo"}),
                    None,
                )
                if not fallback_model:
                    fallback_model = next(
                        (
                            m
                            for m in self.models
                            if m.enabled
                            and m.name != target_model.name
                            and any((p.name or "").strip() != "flow2api" for p in m.providers)
                        ),
                        None,
                    )
                if fallback_model:
                    fallback_params = params.copy()
                    fallback_params["__model_name__"] = fallback_model.name
                    fallback_params.pop("provider", None)
                    images_result, fallback_err = await self._dispatch(
                        params=fallback_params,
                        image_b64_list=image_b64_list,
                        allow_fallback=False,
                    )
                    if images_result:
                        return images_result, None
                    if fallback_err:
                        err = fallback_err

        # å¤„ç†é”™è¯¯ä¿¡æ¯
        if not err:
            err = "æ‰€æœ‰æä¾›å•†å‡ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚"
        return None, err

    def build_message_chain(
        self,
        event: AstrMessageEvent,
        results: list[tuple[str, str]],
        temp_dir=None,
    ) -> list[BaseMessageComponent]:
        """æ„å»ºæ¶ˆæ¯é“¾"""
        msg_chain: list[BaseMessageComponent] = [
            Comp.Reply(id=event.message_obj.message_id)
        ]

        if temp_dir is None:
            temp_dir = self.temp_dir

        image_items: list[tuple[str, str]] = []
        file_items: list[tuple[str, str]] = []

        telegram_force_file = event.platform_meta.name == "telegram" and any(
            (mime or "").startswith("image/") and b64 and len(b64) > MAX_SIZE_B64_LEN
            for mime, b64 in results
        )

        for mime, b64 in results:
            mime = (mime or "").strip()
            if not b64:
                continue
            if telegram_force_file:
                file_items.append((mime or "application/octet-stream", b64))
                continue
            if mime.startswith("image/"):
                image_items.append((mime, b64))
            else:
                file_items.append((mime or "application/octet-stream", b64))

        if file_items:
            save_results = save_images(file_items, temp_dir)
            for name_, path_ in save_results:
                msg_chain.append(Comp.File(name=name_, file=str(path_)))

        if image_items:
            msg_chain.extend(Comp.Image.fromBase64(b64) for _, b64 in image_items)

        return msg_chain

    async def terminate(self):
        """å¯é€‰æ‹©å®ç°å¼‚æ­¥çš„æ’ä»¶é”€æ¯æ–¹æ³•ï¼Œå½“æ’ä»¶è¢«å¸è½½/åœç”¨æ—¶ä¼šè°ƒç”¨ã€‚"""
        # å–æ¶ˆæ‰€æœ‰ç”Ÿæˆä»»åŠ¡
        for task in list(self.running_tasks.values()):
            if not task.done():
                task.cancel()
        await asyncio.gather(*self.running_tasks.values(), return_exceptions=True)
        self.running_tasks.clear()
        # æ¸…ç†ç½‘ç»œå®¢æˆ·ç«¯ä¼šè¯
        await self.http_manager.close_session()
        # å¸è½½å‡½æ•°è°ƒç”¨å·¥å…·
        remove_tools(self.context)
